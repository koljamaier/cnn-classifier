{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define imports\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "#import PIL\n",
    "import os, random\n",
    "\n",
    "from glob import glob\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from IPython.display import display, Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "\n",
    "\n",
    "import copy\n",
    "#import cv2                \n",
    "\n",
    "from io import open\n",
    "import json\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, os.path, random\n",
    "from PIL import Image\n",
    "import requests\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# my imports\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join, abspath\n",
    "from style_transfer.stylize import transfer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All images are resized to 224x224 and normalized\n",
    "# Only training images receive further augmentation\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogImages_style_transfer/valid\n",
      "{'train': 59800, 'valid': 835, 'test': 836}\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'dogImages_style_transfer'\n",
    "print(os.path.join(data_dir, 'valid'))\n",
    "\n",
    "\n",
    "# we create some dictionaries\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'valid', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=5,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'valid', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid', 'test']}\n",
    "print(dataset_sizes)\n",
    "class_names = image_datasets['train'].classes\n",
    "n_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create an S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# this is the S3 data_dir name\n",
    "data_dir = 'dogImages'\n",
    "train_dir = 'train'\n",
    "\n",
    "# set prefix, a descriptive name for a directory  \n",
    "prefix = 'capstone-project'\n",
    "\n",
    "# upload data for the first time; otherwise use the second expression (because the S3 upload takes some time)\n",
    "#train_location = sagemaker_session.upload_data(os.path.join(data_dir), key_prefix=prefix)\n",
    "train_location = 's3://{}/{}/'.format(bucket, prefix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your import and estimator code, here\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix)\n",
    "\n",
    "# note: this PyTorch estimator is specified with code that only\n",
    "# uses the style transferred pictures, but no imgaug preprocessing!\n",
    "source_dir = 'source_pytorch_style_transfer'\n",
    "\n",
    "# instantiate a pytorch estimator\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                    source_dir=source_dir,\n",
    "                    role=role,\n",
    "                    framework_version='1.1.0',\n",
    "                    train_instance_count=1,\n",
    "                    #train_instance_type='ml.c4.xlarge',\n",
    "                    train_instance_type='ml.p2.xlarge',\n",
    "                    output_path=output_path,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    hyperparameters={\n",
    "                        'epochs': 10\n",
    "                    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-05 11:30:00 Starting - Starting the training job...\n",
      "2019-08-05 11:30:02 Starting - Launching requested ML instances...\n",
      "2019-08-05 11:30:40 Starting - Insufficient capacity error from EC2 while launching instances, retrying!......\n",
      "2019-08-05 11:31:39 Starting - Preparing the instances for training.........\n",
      "2019-08-05 11:33:11 Downloading - Downloading input data.............................................\n",
      "2019-08-05 11:41:02 Training - Training image download completed. Training in progress..\n",
      "\u001b[31mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[31mbash: no job control in this shell\u001b[0m\n",
      "\u001b[31m2019-08-05 11:41:03,687 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[31m2019-08-05 11:41:03,714 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[31m2019-08-05 11:41:06,732 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[31m2019-08-05 11:41:07,061 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2019-08-05 11:41:07,061 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2019-08-05 11:41:07,061 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2019-08-05 11:41:07,062 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mCollecting pillow==5.4.1 (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\u001b[0m\n",
      "\u001b[31mCollecting imgaug==0.2.9 (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/17/a9/36de8c0e1ffb2d86f871cac60e5caa910cbbdb5f4741df5ef856c47f4445/imgaug-0.2.9-py2.py3-none-any.whl (753kB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (3.1.0)\u001b[0m\n",
      "\u001b[31mCollecting scikit-image>=0.11.0 (from imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/ab/674e168bf7d0bc597218b3bec858d02c23fbac9ec1fec9cad878c6cee95f/scikit_image-0.15.0-cp36-cp36m-manylinux1_x86_64.whl (26.3MB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (1.3.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (4.0.1.24)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (1.12.0)\u001b[0m\n",
      "\u001b[31mCollecting Shapely (from imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/38/b6/b53f19062afd49bb5abd049aeed36f13bf8d57ef8f3fa07a5203531a0252/Shapely-1.6.4.post2-cp36-cp36m-manylinux1_x86_64.whl (1.5MB)\u001b[0m\n",
      "\u001b[31mCollecting imageio (from imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/af/0a/943c965d372dae0b1f1482677d29030ab834351a61a9a632fd62f27f1523/imageio-2.5.0-py3-none-any.whl (3.3MB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (1.16.4)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (2.4.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (1.1.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (0.10.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (2.8.0)\u001b[0m\n",
      "\u001b[31mCollecting PyWavelets>=0.4.0 (from scikit-image>=0.11.0->imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/cd/528dba0b474b08f6f9a3a5e1b4bb23d8e33ed5d9f0e321cc967c2607df05/PyWavelets-1.0.3-cp36-cp36m-manylinux1_x86_64.whl (4.4MB)\u001b[0m\n",
      "\u001b[31mCollecting networkx>=2.0 (from scikit-image>=0.11.0->imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/85/08/f20aef11d4c343b557e5de6b9548761811eb16e438cee3d32b1c66c8566b/networkx-2.3.zip (1.7MB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (41.0.1)\u001b[0m\n",
      "\u001b[31mCollecting decorator>=4.3.0 (from networkx>=2.0->scikit-image>=0.11.0->imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/5f/88/0075e461560a1e750a0dcbf77f1d9de775028c37a19a346a6c565a257399/decorator-4.4.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: train, networkx\n",
      "  Running setup.py bdist_wheel for train: started\u001b[0m\n",
      "\u001b[31m  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-wj3x4udf/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "  Running setup.py bdist_wheel for networkx: started\u001b[0m\n",
      "\u001b[31m  Running setup.py bdist_wheel for networkx: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/de/63/64/3699be2a9d0ccdb37c7f16329acf3863fd76eda58c39c737af\u001b[0m\n",
      "\u001b[31mSuccessfully built train networkx\u001b[0m\n",
      "\u001b[31msagemaker-pytorch-container 1.2 has requirement Pillow==6.0.0, but you'll have pillow 5.4.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mInstalling collected packages: pillow, PyWavelets, imageio, decorator, networkx, scikit-image, Shapely, imgaug, train\n",
      "  Found existing installation: Pillow 6.0.0\n",
      "    Uninstalling Pillow-6.0.0:\u001b[0m\n",
      "\u001b[31m      Successfully uninstalled Pillow-6.0.0\u001b[0m\n",
      "\u001b[31mSuccessfully installed PyWavelets-1.0.3 Shapely-1.6.4.post2 decorator-4.4.0 imageio-2.5.0 imgaug-0.2.9 networkx-2.3 pillow-5.4.1 scikit-image-0.15.0 train-1.0.0\u001b[0m\n",
      "\u001b[31mYou are using pip version 18.1, however version 19.2.1 is available.\u001b[0m\n",
      "\u001b[31mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31m2019-08-05 11:41:15,730 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2019-08-05-11-30-00-513\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-central-1-505649883860/sagemaker-pytorch-2019-08-05-11-30-00-513/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[31mSM_HPS={\"epochs\":10}\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://sagemaker-eu-central-1-505649883860/sagemaker-pytorch-2019-08-05-11-30-00-513/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2019-08-05-11-30-00-513\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-central-1-505649883860/sagemaker-pytorch-2019-08-05-11-30-00-513/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--epochs\",\"10\"]\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[31mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m train --epochs 10\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mUsing device cuda.\u001b[0m\n",
      "\u001b[31mGet train data loader.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mEpoch: 1 #011Training Loss: 3.636029 #011Validation Loss: 1.318098\u001b[0m\n",
      "\u001b[31mEpoch: 2 #011Training Loss: 2.686004 #011Validation Loss: 0.844991\u001b[0m\n",
      "\u001b[31mEpoch: 3 #011Training Loss: 2.387923 #011Validation Loss: 0.685585\u001b[0m\n",
      "\u001b[31mEpoch: 4 #011Training Loss: 2.232464 #011Validation Loss: 0.606484\u001b[0m\n",
      "\u001b[31mEpoch: 5 #011Training Loss: 2.129745 #011Validation Loss: 0.561718\u001b[0m\n",
      "\u001b[31mEpoch: 6 #011Training Loss: 2.060371 #011Validation Loss: 0.529383\u001b[0m\n",
      "\u001b[31mEpoch: 7 #011Training Loss: 2.005694 #011Validation Loss: 0.505579\u001b[0m\n",
      "\u001b[31mEpoch: 8 #011Training Loss: 1.954784 #011Validation Loss: 0.488833\u001b[0m\n",
      "\u001b[31mEpoch: 9 #011Training Loss: 1.920151 #011Validation Loss: 0.476198\u001b[0m\n",
      "\u001b[31mEpoch: 10 #011Training Loss: 1.887669 #011Validation Loss: 0.465194\u001b[0m\n",
      "\u001b[31m2019-08-05 13:30:44,285 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2019-08-05 13:30:45 Uploading - Uploading generated training model\n",
      "2019-08-05 13:32:00 Completed - Training job completed\n",
      "Billable seconds: 7130\n",
      "CPU times: user 12.9 s, sys: 551 ms, total: 13.5 s\n",
      "Wall time: 2h 2min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train your estimator on S3 training data\n",
    "estimator.fit({'train': train_location})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-eu-central-1-505649883860/capstone-project/sagemaker-pytorch-2019-08-05-11-30-00-513/output/model.tar.gz\n",
      "CPU times: user 18.8 ms, sys: 100 Âµs, total: 18.9 ms\n",
      "Wall time: 94.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# importing PyTorchModel\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "print(estimator.model_data)\n",
    "\n",
    "# Create a model from the trained estimator data\n",
    "# And point to the prediction script\n",
    "model = PyTorchModel(model_data=estimator.model_data,\n",
    "                     role = role,\n",
    "                     framework_version='1.1.0',\n",
    "                     entry_point='predict.py',\n",
    "                     source_dir=source_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "# ATTENTION: Please use the ml.t2.large instance here. Otherwise the deployment will fail because of resource constraints\n",
    "# predictor = model.deploy(initial_instance_count=1, instance_type='ml.t2.medium')\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.t2.large')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5, 10, 33, 67, 94])\n",
      "preds is [122  10  33  67  94]\n",
      "tensor([ 17,  72, 112,  64, 113])\n",
      "preds is [ 17  62 112  64 113]\n",
      "tensor([70, 42, 44, 60, 64])\n",
      "preds is [ 70  66 117  60  64]\n",
      "tensor([126,  80,   6,  71, 119])\n",
      "preds is [126  80   6  71 119]\n",
      "tensor([ 62, 123,  39,  70,   4])\n",
      "preds is [ 62 123  39  70   4]\n",
      "tensor([37, 14, 73,  2, 81])\n",
      "preds is [ 37  14  25   2 124]\n",
      "tensor([45, 43, 31, 35, 93])\n",
      "preds is [45 43 31 35 93]\n",
      "tensor([ 94,  43,   4,  85, 111])\n",
      "preds is [ 78  43   4  85 111]\n",
      "tensor([106,  74,  32,  33,  53])\n",
      "preds is [106  74  32  33  53]\n",
      "tensor([ 12,  87,  33,   7, 105])\n",
      "preds is [ 12  87  33   7 105]\n",
      "tensor([ 68, 124,  10,  91,  56])\n",
      "preds is [ 68 124  42  91  56]\n",
      "tensor([61, 78, 70, 81, 18])\n",
      "preds is [61 78 70 81 18]\n",
      "tensor([  3,  48,   5,  61, 130])\n",
      "preds is [  3  48   5  61 130]\n",
      "tensor([  2,   8,  46, 119,  88])\n",
      "preds is [  2  34  46 119  88]\n",
      "tensor([122,  16, 114,  44,  77])\n",
      "preds is [122  16 114  44 121]\n",
      "tensor([ 38, 110,  41,  42,  37])\n",
      "preds is [ 38 110  41  42  37]\n",
      "tensor([ 8, 37, 56, 41, 17])\n",
      "preds is [ 8 37 56 41 17]\n",
      "tensor([66, 13, 63, 37, 14])\n",
      "preds is [66 13 63 37 14]\n",
      "tensor([78, 10, 76, 88, 13])\n",
      "preds is [94 10 76 88 13]\n",
      "tensor([114, 124,  55, 130,  68])\n",
      "preds is [114 124  55 130  68]\n",
      "tensor([ 13, 132,  45,  48, 120])\n",
      "preds is [ 13 132  76 123 120]\n",
      "tensor([ 39, 102,  55,  32,  56])\n",
      "preds is [ 39 102 118  32  56]\n",
      "tensor([39, 78, 72, 77,  0])\n",
      "preds is [39 78 73 77  0]\n",
      "tensor([ 15, 100,   2, 115,  11])\n",
      "preds is [ 15 100   2 115  11]\n",
      "tensor([ 59, 105,  51,   9,  19])\n",
      "preds is [ 59 105  51   9  19]\n",
      "tensor([132,  82,  72,  40,  11])\n",
      "preds is [132  82 130  40  28]\n",
      "tensor([ 87, 108,  26,  14,  10])\n",
      "preds is [ 87 108  26  14  10]\n",
      "tensor([ 12,   4, 115, 102,  59])\n",
      "preds is [ 12   4 115  39  59]\n",
      "tensor([ 20, 100,  92,   3,  74])\n",
      "preds is [ 20 100  25   3 118]\n",
      "tensor([100,  38,  15,  10,  83])\n",
      "preds is [100  38  15  42  83]\n",
      "tensor([93, 20, 83,  3, 80])\n",
      "preds is [93 25 83  3 80]\n",
      "tensor([116,  28, 118,  38,   4])\n",
      "preds is [116  28 118  38   4]\n",
      "tensor([ 62,  65,   0, 111,  14])\n",
      "preds is [ 62  65   0 111  14]\n",
      "tensor([20, 92, 54, 23, 54])\n",
      "preds is [20 73 54 23 54]\n",
      "tensor([ 50, 123,  51,  25,  90])\n",
      "preds is [ 50 123  51 124  90]\n",
      "tensor([33, 56,  7, 11, 27])\n",
      "preds is [33 56  7 11 27]\n",
      "tensor([ 56,  44,  43, 124,  21])\n",
      "preds is [ 56  44  43 124  21]\n",
      "tensor([110, 125,  15,  58,  44])\n",
      "preds is [110 125  15  69  44]\n",
      "tensor([ 54,  26,  35, 117,  28])\n",
      "preds is [ 54  26  35 117  28]\n",
      "tensor([128,  86,  46,  87,  43])\n",
      "preds is [128  86  46  87  43]\n",
      "tensor([ 43,  91, 106,  55,   9])\n",
      "preds is [ 40  91 106  60   9]\n",
      "tensor([ 50, 106,  51,  13,  14])\n",
      "preds is [ 50 106  51  42  14]\n",
      "tensor([ 61,  24, 129,  43, 121])\n",
      "preds is [129  55 129   7 121]\n",
      "tensor([ 25,  83,  60,  28, 122])\n",
      "preds is [ 25  83  62  28 122]\n",
      "tensor([ 36, 110,  89,  85,   7])\n",
      "preds is [ 36 110  89  85   7]\n",
      "tensor([ 22, 111,  11, 112,  78])\n",
      "preds is [ 22 111  11 112  94]\n",
      "tensor([101,  30,  32,  11,  15])\n",
      "preds is [101  30  32  11  15]\n",
      "tensor([ 74, 126,  86,  18,  85])\n",
      "preds is [ 74 126  86  18  85]\n",
      "tensor([  1,  98, 100,   6,  42])\n",
      "preds is [  1  98 100   6  42]\n",
      "tensor([ 20, 108,  45,  53,  60])\n",
      "preds is [ 20 108  45  53  72]\n",
      "tensor([106, 108,  87,  32,  52])\n",
      "preds is [106 108   8  73  52]\n",
      "tensor([ 41,  67,  42,  89, 114])\n",
      "preds is [ 41  67  95  89 114]\n",
      "tensor([ 4,  8, 37, 13, 34])\n",
      "preds is [  4  87 132  13  34]\n",
      "tensor([106,   7, 118,  67,  33])\n",
      "preds is [106   7 118  67  33]\n",
      "tensor([ 85,  45, 122,  29,  17])\n",
      "preds is [ 85  76 122  29  17]\n",
      "tensor([40, 23, 12, 60, 62])\n",
      "preds is [40 23 12 60 62]\n",
      "tensor([103,  54,  47,  17,   9])\n",
      "preds is [103 123  47  17   9]\n",
      "tensor([ 56,  36, 119,  35, 114])\n",
      "preds is [ 56  36 119  35 114]\n",
      "tensor([ 21,  27,  79, 113,  27])\n",
      "preds is [ 21  27  79 113  61]\n",
      "tensor([77, 51, 45, 30,  1])\n",
      "preds is [80 51 45 30 52]\n",
      "tensor([89, 42,  4, 81, 28])\n",
      "preds is [89 42  4 99 28]\n",
      "tensor([ 86,  46,  34, 103, 128])\n",
      "preds is [ 86  46  34 103  50]\n",
      "tensor([ 69, 114,  86,  70,  89])\n",
      "preds is [101 114  86  70  89]\n",
      "tensor([  1, 117,  85,  57,  62])\n",
      "preds is [  1 117  85  57  62]\n",
      "tensor([38, 33, 70, 16, 14])\n",
      "preds is [ 38  33 108  16  14]\n",
      "tensor([109,  71,  70,  48, 117])\n",
      "preds is [109  71  70  48 117]\n",
      "tensor([  1, 127,  26,  67,  50])\n",
      "preds is [ 35 127  26  67  50]\n",
      "tensor([128, 117,  65, 108,  59])\n",
      "preds is [128 117  65  91  59]\n",
      "tensor([ 41,  26, 107,  80,  22])\n",
      "preds is [41 26 66 80 22]\n",
      "tensor([ 40, 101, 119,  98,  31])\n",
      "preds is [ 40 101 119  98  31]\n",
      "tensor([59, 23, 96, 11, 86])\n",
      "preds is [59 23  2 11 86]\n",
      "tensor([  3, 116,  95,  49,  68])\n",
      "preds is [  3 116  46  49  68]\n",
      "tensor([ 75,   4,  71,  41, 112])\n",
      "preds is [ 75   4  95  41 112]\n",
      "tensor([56, 12, 13, 29,  6])\n",
      "preds is [ 56 110  13  29   6]\n",
      "tensor([113,  45,  36,  57,   0])\n",
      "preds is [113  45  84  57   0]\n",
      "tensor([117, 115,  63,  99,  29])\n",
      "preds is [117 115  45  99  29]\n",
      "tensor([ 33,  52,  90,  74, 132])\n",
      "preds is [ 33 129  90 126 132]\n",
      "tensor([95,  2, 36, 55, 97])\n",
      "preds is [39  2 36 69 97]\n",
      "tensor([122,  40,  68, 105,  26])\n",
      "preds is [114  33  68 105  26]\n",
      "tensor([ 15,  95,  28,   0, 129])\n",
      "preds is [15 95 28  0 84]\n",
      "tensor([70, 25, 15, 60, 80])\n",
      "preds is [70 25 15 62 69]\n",
      "tensor([ 16,  82, 104,  87,  13])\n",
      "preds is [ 16  82 104  87  13]\n",
      "tensor([102,  47, 129, 129,  94])\n",
      "preds is [102 107 129  84  78]\n",
      "tensor([123,  57,  18,  49,  22])\n",
      "preds is [123  57  18  49  22]\n",
      "tensor([ 82,   7,   4,  56, 103])\n",
      "preds is [ 82   7   4  56 103]\n",
      "tensor([ 0, 85, 40,  1, 21])\n",
      "preds is [ 0 85 40  1 21]\n",
      "tensor([131, 108,  76,  96,  98])\n",
      "preds is [131 108  76  96  81]\n",
      "tensor([105,  13,  38,  58, 104])\n",
      "preds is [105  13  38  69 104]\n",
      "tensor([69, 87, 19, 38, 54])\n",
      "preds is [101 123  19  38  54]\n",
      "tensor([ 91,  81, 109,   4,  14])\n",
      "preds is [ 91  81 117   4  14]\n",
      "tensor([ 29,  69,  39,  64, 105])\n",
      "preds is [ 29  69  39  64 105]\n",
      "tensor([41, 79,  5, 46, 78])\n",
      "preds is [41 79  5 46 94]\n",
      "tensor([116,  78,  47,  34,  44])\n",
      "preds is [116  94 122  65  44]\n",
      "tensor([94, 31, 50, 21, 13])\n",
      "preds is [ 94  31 105  21  13]\n",
      "tensor([111,  63,  25,  61,  50])\n",
      "preds is [111  45  73  61  50]\n",
      "tensor([106, 112,  69,   2, 127])\n",
      "preds is [106 112  69   2 127]\n",
      "tensor([28, 81,  6,  9, 31])\n",
      "preds is [28 81 95 94 31]\n",
      "tensor([  0,  45,  90, 128, 113])\n",
      "preds is [  0  45  90 128 113]\n",
      "tensor([ 29,  57,  82,  19, 131])\n",
      "preds is [ 29  57  82  19 131]\n",
      "tensor([ 63, 102,  74,  73, 124])\n",
      "preds is [ 63 102 113  73 124]\n",
      "tensor([ 53,  80,  65,  97, 126])\n",
      "preds is [ 53  80  65  97 132]\n",
      "tensor([39, 55, 22, 93, 52])\n",
      "preds is [39 85 22 93 62]\n",
      "tensor([97, 12,  9, 96, 76])\n",
      "preds is [ 97  12   9 124  76]\n",
      "tensor([49, 38, 78, 97,  5])\n",
      "preds is [ 49  38 125  97   5]\n",
      "tensor([60, 31, 35, 73, 93])\n",
      "preds is [76 31 35 73 93]\n",
      "tensor([60, 37, 98, 83, 89])\n",
      "preds is [ 60  37  98 117  89]\n",
      "tensor([ 86,   5, 126,  24,  60])\n",
      "preds is [ 86   5 126  24  60]\n",
      "tensor([81, 26, 40, 15, 52])\n",
      "preds is [81 26 40 15 75]\n",
      "tensor([ 23, 125, 110,  55,  50])\n",
      "preds is [ 23 125 110  55  50]\n",
      "tensor([ 67,  80,  66, 117,  96])\n",
      "preds is [ 67  80 117 117 124]\n",
      "tensor([ 20, 121,  31,  55, 100])\n",
      "preds is [ 20  36  31 113 100]\n",
      "tensor([  6,  20, 104,  19, 118])\n",
      "preds is [  6  20 104  19 118]\n",
      "tensor([ 58,  39, 105,  83,  68])\n",
      "preds is [ 58  39 105 117  68]\n",
      "tensor([75, 59, 97, 30, 58])\n",
      "preds is [75 59 97 53 69]\n",
      "tensor([ 75,  23,  90, 116,  99])\n",
      "preds is [75 23 90 37 99]\n",
      "tensor([34,  1,  7, 84, 35])\n",
      "preds is [ 95  61   7 129  35]\n",
      "tensor([62, 40, 41, 81, 99])\n",
      "preds is [ 62  43  41  99 103]\n",
      "tensor([57, 84, 90, 46, 26])\n",
      "preds is [100 129  90  46  26]\n",
      "tensor([ 17, 109, 126,  36, 117])\n",
      "preds is [ 17  13 132  36 117]\n",
      "tensor([21,  5, 51, 79, 73])\n",
      "preds is [21  5 62 79 92]\n",
      "tensor([ 88, 127,  17,  30,  43])\n",
      "preds is [ 88 127  17  30  43]\n",
      "tensor([ 10, 128,  50,   6,  65])\n",
      "preds is [ 10 128  50   6  65]\n",
      "tensor([107,  47,  49,  79,  34])\n",
      "preds is [107  47  49  79  34]\n",
      "tensor([ 30, 123, 100,  59, 119])\n",
      "preds is [ 30 123 100  59 119]\n",
      "tensor([73, 19, 53, 71, 82])\n",
      "preds is [ 73  19  53 121  82]\n",
      "tensor([ 96,  28,   3, 125, 114])\n",
      "preds is [ 96  28   3 125 114]\n",
      "tensor([67, 55, 67, 47, 18])\n",
      "preds is [ 67  55  67 114  18]\n",
      "tensor([ 28,  35,  16, 114, 112])\n",
      "preds is [ 28  35  16 114 112]\n",
      "tensor([ 98, 122,  11,  16,  49])\n",
      "preds is [ 98 122  11  16  59]\n",
      "tensor([ 27, 114,  24,   4,  19])\n",
      "preds is [ 27 114  24   4  19]\n",
      "tensor([ 22,  21, 103,  75,  94])\n",
      "preds is [ 22  20 103  75  78]\n",
      "tensor([ 57,  19,  14,   0, 120])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds is [ 57  19  14  98 120]\n",
      "tensor([102,  63,  38,  31,  75])\n",
      "preds is [40 63 38 31 75]\n",
      "tensor([29, 48, 28, 50, 22])\n",
      "preds is [29 48 28 50 22]\n",
      "tensor([ 71,  91,  91,   8, 116])\n",
      "preds is [121  91  91  87 116]\n",
      "tensor([67, 86, 37, 46, 16])\n",
      "preds is [105  86  37  46  16]\n",
      "tensor([ 20,  69, 120,  76,  88])\n",
      "preds is [ 20  69 120  76  16]\n",
      "tensor([128,   7,  35,  43,  40])\n",
      "preds is [75  7 35 43 40]\n",
      "tensor([ 22,  64,  45, 132,  23])\n",
      "preds is [ 22  79  45 132  23]\n",
      "tensor([ 77,  68,  96,  40, 127])\n",
      "preds is [ 77  68   2  40 127]\n",
      "tensor([86, 29, 20, 47, 75])\n",
      "preds is [86 29 20 47 75]\n",
      "tensor([129,  82,  55,  52,  69])\n",
      "preds is [129  82  55  63  69]\n",
      "tensor([31, 44, 92, 72, 62])\n",
      "preds is [31 44 92 36 67]\n",
      "tensor([ 52,   1,   3,  11, 130])\n",
      "preds is [52  1  3 11 72]\n",
      "tensor([ 23,  95, 111,  90,   2])\n",
      "preds is [ 23  95 111  90   2]\n",
      "tensor([53, 72, 95, 18, 17])\n",
      "preds is [ 53 130  95  18  17]\n",
      "tensor([  9,  84, 102,  66,  75])\n",
      "preds is [  9  84 102  83  75]\n",
      "tensor([62,  7, 28, 89, 10])\n",
      "preds is [ 62   7  28 119  10]\n",
      "tensor([66, 16, 45, 34, 39])\n",
      "preds is [66 16 45 34 39]\n",
      "tensor([75, 90, 53, 54, 19])\n",
      "preds is [75 90 53 54 19]\n",
      "tensor([ 68,  12, 111,   3,  26])\n",
      "preds is [ 68 126 111  42  26]\n",
      "tensor([ 14, 110,  71,  23, 121])\n",
      "preds is [ 14 110  71  23  71]\n",
      "tensor([ 16,  15,  59,  44, 109])\n",
      "preds is [ 16   6  59 117 117]\n",
      "tensor([111,  42,  84,  58,  25])\n",
      "preds is [111 107  84  69  32]\n",
      "tensor([102,   1,  99,   6,  10])\n",
      "preds is [102   1  99   6 117]\n",
      "tensor([101,  36,  46,  56,  61])\n",
      "preds is [101  62  46  56 129]\n",
      "tensor([ 53, 121,  57, 115,  48])\n",
      "preds is [ 53  71  57 115  48]\n",
      "tensor([103,  88,  47,  59,  30])\n",
      "preds is [103  88  47  59  30]\n",
      "tensor([ 77, 118,  51,  35,  61])\n",
      "preds is [77 16 51 35 61]\n",
      "tensor([  5,  89,  79, 131,  54])\n",
      "preds is [  5  89  79 131  54]\n",
      "tensor([85, 88,  0,  3, 58])\n",
      "preds is [85 88  0  4 58]\n",
      "tensor([ 32,  89,  24, 123,  49])\n",
      "preds is [ 32  89  24 123  59]\n",
      "tensor([ 83, 104,  94,  64,  11])\n",
      "preds is [114 104  94  64  11]\n",
      "tensor([ 33, 123,  22,  93,  88])\n",
      "preds is [ 33 123  22  93  88]\n",
      "tensor([116, 107,  41,  92,  70])\n",
      "preds is [116 109 110  92  70]\n",
      "tensor([14, 38, 10, 48, 30])\n",
      "preds is [ 14  38  10 132  30]\n",
      "tensor([80, 81,  5, 18, 76])\n",
      "preds is [ 80 100   5  18  76]\n",
      "tensor([78])\n",
      "preds is 78\n",
      "Acc: 81.58%\n",
      "tensor(0.8158, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "def test_acc(test_set, predictor):\n",
    "    ''' \n",
    "    This method calculates our accuracy metric. For this, it will send \n",
    "    batches of data to the endpoint and receive the predictions\n",
    "    '''\n",
    "    test_acc = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in test_set:\n",
    "        print(labels)\n",
    "        test_y_preds = predictor.predict(inputs)\n",
    "\n",
    "        _, preds_tensor = torch.max(torch.from_numpy(test_y_preds), 1)\n",
    "        preds = np.squeeze(preds_tensor.numpy()) if not use_cuda else np.squeeze(preds_tensor.cpu().numpy())\n",
    "\n",
    "        print(f\"preds is {preds}\")\n",
    "    \n",
    "        # compare the batch of predictions with the ground truth of labels\n",
    "        running_corrects += torch.sum(torch.from_numpy(preds) == labels)\n",
    "\n",
    "    test_acc = running_corrects.double() / len(test_set.dataset)\n",
    "\n",
    "    print('Acc: {:.2f}%'.format(test_acc*100))\n",
    "\n",
    "    return test_acc\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "testacc=test_acc(iter(dataloaders['test']), predictor)\n",
    "print(testacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we want to see how our baseline model keeps up. For this, we first need to upload the original dogImages (no style transferred images includes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# this is the S3 data_dir name\n",
    "data_dir = 'dogImages'\n",
    "\n",
    "# set prefix, a descriptive name for a directory  \n",
    "prefix = 'capstone-project-orig-data'\n",
    "\n",
    "# upload data for the first time; otherwise use the second expression (because the S3 upload takes some time)\n",
    "#train_location_orig_data = sagemaker_session.upload_data(os.path.join(data_dir), key_prefix=prefix)\n",
    "train_location_orig_data = 's3://{}/{}/'.format(bucket, prefix) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimator itself and the deployment is exactly the same. What a great benefit of our structured SageMaker deployment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your import and estimator code, here\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix)\n",
    "\n",
    "# note: this PyTorch estimator is specified with code that only\n",
    "# uses the style transferred pictures, but no imgaug preprocessing!\n",
    "source_dir = 'source_pytorch_style_transfer'\n",
    "\n",
    "# instantiate a pytorch estimator\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                    source_dir=source_dir,\n",
    "                    role=role,\n",
    "                    framework_version='1.1.0',\n",
    "                    train_instance_count=1,\n",
    "                    #train_instance_type='ml.c4.xlarge',\n",
    "                    train_instance_type='ml.p2.xlarge',\n",
    "                    output_path=output_path,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    hyperparameters={\n",
    "                        'epochs': 10\n",
    "                    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-05 15:58:49 Starting - Starting the training job...\n",
      "2019-08-05 15:58:51 Starting - Launching requested ML instances...\n",
      "2019-08-05 15:59:21 Starting - Insufficient capacity error from EC2 while launching instances, retrying!......\n",
      "2019-08-05 16:00:20 Starting - Preparing the instances for training......\n",
      "2019-08-05 16:01:33 Downloading - Downloading input data.........\n",
      "2019-08-05 16:03:04 Training - Downloading the training image..\n",
      "\u001b[31mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[31mbash: no job control in this shell\u001b[0m\n",
      "\u001b[31m2019-08-05 16:03:23,390 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[31m2019-08-05 16:03:23,414 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[31m2019-08-05 16:03:29,640 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[31m2019-08-05 16:03:29,864 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2019-08-05 16:03:29,865 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2019-08-05 16:03:29,865 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2019-08-05 16:03:29,865 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mCollecting pillow==5.4.1 (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\u001b[0m\n",
      "\u001b[31mCollecting imgaug==0.2.9 (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/17/a9/36de8c0e1ffb2d86f871cac60e5caa910cbbdb5f4741df5ef856c47f4445/imgaug-0.2.9-py2.py3-none-any.whl (753kB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (4.0.1.24)\u001b[0m\n",
      "\u001b[31mCollecting Shapely (from imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/38/b6/b53f19062afd49bb5abd049aeed36f13bf8d57ef8f3fa07a5203531a0252/Shapely-1.6.4.post2-cp36-cp36m-manylinux1_x86_64.whl (1.5MB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (1.3.0)\u001b[0m\n",
      "\u001b[31mCollecting scikit-image>=0.11.0 (from imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/ab/674e168bf7d0bc597218b3bec858d02c23fbac9ec1fec9cad878c6cee95f/scikit_image-0.15.0-cp36-cp36m-manylinux1_x86_64.whl (26.3MB)\u001b[0m\n",
      "\u001b[31mCollecting imageio (from imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/af/0a/943c965d372dae0b1f1482677d29030ab834351a61a9a632fd62f27f1523/imageio-2.5.0-py3-none-any.whl (3.3MB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (1.12.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (3.1.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (1.16.4)\u001b[0m\n",
      "\u001b[31mCollecting PyWavelets>=0.4.0 (from scikit-image>=0.11.0->imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/cd/528dba0b474b08f6f9a3a5e1b4bb23d8e33ed5d9f0e321cc967c2607df05/PyWavelets-1.0.3-cp36-cp36m-manylinux1_x86_64.whl (4.4MB)\u001b[0m\n",
      "\u001b[31mCollecting networkx>=2.0 (from scikit-image>=0.11.0->imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/85/08/f20aef11d4c343b557e5de6b9548761811eb16e438cee3d32b1c66c8566b/networkx-2.3.zip (1.7MB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (1.1.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (0.10.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (2.4.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (2.8.0)\u001b[0m\n",
      "\u001b[31mCollecting decorator>=4.3.0 (from networkx>=2.0->scikit-image>=0.11.0->imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/5f/88/0075e461560a1e750a0dcbf77f1d9de775028c37a19a346a6c565a257399/decorator-4.4.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (41.0.1)\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: train, networkx\n",
      "  Running setup.py bdist_wheel for train: started\u001b[0m\n",
      "\u001b[31m  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-6gx2f7df/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "  Running setup.py bdist_wheel for networkx: started\u001b[0m\n",
      "\u001b[31m  Running setup.py bdist_wheel for networkx: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/de/63/64/3699be2a9d0ccdb37c7f16329acf3863fd76eda58c39c737af\u001b[0m\n",
      "\u001b[31mSuccessfully built train networkx\u001b[0m\n",
      "\u001b[31msagemaker-pytorch-container 1.2 has requirement Pillow==6.0.0, but you'll have pillow 5.4.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mInstalling collected packages: pillow, Shapely, imageio, PyWavelets, decorator, networkx, scikit-image, imgaug, train\n",
      "  Found existing installation: Pillow 6.0.0\n",
      "    Uninstalling Pillow-6.0.0:\n",
      "      Successfully uninstalled Pillow-6.0.0\u001b[0m\n",
      "\u001b[31mSuccessfully installed PyWavelets-1.0.3 Shapely-1.6.4.post2 decorator-4.4.0 imageio-2.5.0 imgaug-0.2.9 networkx-2.3 pillow-5.4.1 scikit-image-0.15.0 train-1.0.0\u001b[0m\n",
      "\u001b[31mYou are using pip version 18.1, however version 19.2.1 is available.\u001b[0m\n",
      "\u001b[31mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31m2019-08-05 16:03:37,669 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2019-08-05-15-58-48-712\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-central-1-505649883860/sagemaker-pytorch-2019-08-05-15-58-48-712/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[31mSM_HPS={\"epochs\":10}\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://sagemaker-eu-central-1-505649883860/sagemaker-pytorch-2019-08-05-15-58-48-712/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2019-08-05-15-58-48-712\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-central-1-505649883860/sagemaker-pytorch-2019-08-05-15-58-48-712/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--epochs\",\"10\"]\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[31mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m train --epochs 10\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-08-05 16:03:22 Training - Training image download completed. Training in progress.\u001b[31mUsing device cuda.\u001b[0m\n",
      "\u001b[31mGet train data loader.\u001b[0m\n",
      "\u001b[31mEpoch: 1 #011Training Loss: 3.712942 #011Validation Loss: 2.561787\u001b[0m\n",
      "\u001b[31mEpoch: 2 #011Training Loss: 2.093467 #011Validation Loss: 1.663501\u001b[0m\n",
      "\u001b[31mEpoch: 3 #011Training Loss: 1.476688 #011Validation Loss: 1.265527\u001b[0m\n",
      "\u001b[31mEpoch: 4 #011Training Loss: 1.181037 #011Validation Loss: 1.050675\u001b[0m\n",
      "\u001b[31mEpoch: 5 #011Training Loss: 1.011723 #011Validation Loss: 0.915356\u001b[0m\n",
      "\u001b[31mEpoch: 6 #011Training Loss: 0.890234 #011Validation Loss: 0.823472\u001b[0m\n",
      "\u001b[31mEpoch: 7 #011Training Loss: 0.804099 #011Validation Loss: 0.756152\u001b[0m\n",
      "\u001b[31mEpoch: 8 #011Training Loss: 0.736964 #011Validation Loss: 0.703578\u001b[0m\n",
      "\u001b[31mEpoch: 9 #011Training Loss: 0.688688 #011Validation Loss: 0.662970\u001b[0m\n",
      "\u001b[31mEpoch: 10 #011Training Loss: 0.645880 #011Validation Loss: 0.631162\u001b[0m\n",
      "\u001b[31m2019-08-05 16:18:31,413 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2019-08-05 16:18:35 Uploading - Uploading generated training model\n",
      "2019-08-05 16:19:51 Completed - Training job completed\n",
      "Billable seconds: 1099\n",
      "CPU times: user 2.36 s, sys: 106 ms, total: 2.46 s\n",
      "Wall time: 21min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train your estimator on S3 training data\n",
    "estimator.fit({'train': train_location_orig_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-eu-central-1-505649883860/capstone-project-orig-data/sagemaker-pytorch-2019-08-05-15-58-48-712/output/model.tar.gz\n",
      "CPU times: user 17.5 ms, sys: 46 Âµs, total: 17.5 ms\n",
      "Wall time: 68.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# importing PyTorchModel\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "print(estimator.model_data)\n",
    "\n",
    "# Create a model from the trained estimator data\n",
    "# And point to the prediction script\n",
    "model = PyTorchModel(model_data=estimator.model_data,\n",
    "                     role = role,\n",
    "                     framework_version='1.1.0',\n",
    "                     entry_point='predict.py',\n",
    "                     source_dir=source_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.t2.large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([102,  12,   9, 105,  55])\n",
      "preds is [102 111   9 105  60]\n",
      "tensor([  4, 123, 106,   0, 132])\n",
      "preds is [  4 123 106   0 126]\n",
      "tensor([17,  0, 61, 48, 92])\n",
      "preds is [17  0 61 48 92]\n",
      "tensor([ 46, 123,  76,  22,  50])\n",
      "preds is [ 46 123  76  22  50]\n",
      "tensor([ 59,  50, 126,  30,   0])\n",
      "preds is [ 59  50 126  30   0]\n",
      "tensor([ 52,  98, 110,  44,  56])\n",
      "preds is [ 75  98 110  44  56]\n",
      "tensor([20, 85, 60, 21, 14])\n",
      "preds is [20 85 76 21 14]\n",
      "tensor([ 59,  10, 128, 108,   7])\n",
      "preds is [ 59  10  50 108   7]\n",
      "tensor([111,  22,  31, 129,  81])\n",
      "preds is [111  22  31 129  81]\n",
      "tensor([68, 30, 38, 45, 36])\n",
      "preds is [68 30 38 76 36]\n",
      "tensor([ 35, 109,  14,  81,  62])\n",
      "preds is [ 35 117  14  81  67]\n",
      "tensor([132,  10, 122,  28,   1])\n",
      "preds is [132  10 122  28   1]\n",
      "tensor([57, 99, 13, 81,  4])\n",
      "preds is [57 99 13 81  4]\n",
      "tensor([45, 46, 68, 55, 19])\n",
      "preds is [45 46 68 55 19]\n",
      "tensor([ 42,   3,   9, 103,  72])\n",
      "preds is [ 42   3   9 103  36]\n",
      "tensor([ 4, 93, 85, 45, 32])\n",
      "preds is [ 4 93 85 45 73]\n",
      "tensor([ 78,   4, 132,  47,  18])\n",
      "preds is [ 94   4 132  47  18]\n",
      "tensor([109,   1,  25,  94,  77])\n",
      "preds is [127 116  25  94  31]\n",
      "tensor([ 57, 101,  98,  36, 116])\n",
      "preds is [ 57 101  98  36 116]\n",
      "tensor([84, 23, 91,  5,  0])\n",
      "preds is [84 23 91  5  0]\n",
      "tensor([ 71,  52, 121, 121,  50])\n",
      "preds is [ 71  52 121  71  50]\n",
      "tensor([ 75,  89,  13,  46, 100])\n",
      "preds is [ 75  89  42  46 100]\n",
      "tensor([17, 17, 69,  3, 79])\n",
      "preds is [17 17 69  3 79]\n",
      "tensor([116,  45,  34,  90,   6])\n",
      "preds is [116  45  34  90   6]\n",
      "tensor([38, 33, 82, 75, 68])\n",
      "preds is [38 33 82 75 68]\n",
      "tensor([ 33,  15, 103,  20,   3])\n",
      "preds is [ 33  15 103  20   3]\n",
      "tensor([ 48,  26,  34,  29, 104])\n",
      "preds is [ 48  26  34  29 104]\n",
      "tensor([ 89,  12, 101,   1,   5])\n",
      "preds is [119  12 101   1   5]\n",
      "tensor([ 1, 82, 35, 78, 96])\n",
      "preds is [  1  82  35 125  96]\n",
      "tensor([ 64,  83, 116,  84,  80])\n",
      "preds is [ 64 117 116 129  80]\n",
      "tensor([ 28,  70,  13, 100,  30])\n",
      "preds is [ 28  70  13 100  30]\n",
      "tensor([ 37,  58, 105,  67,  35])\n",
      "preds is [132  69 105  67  35]\n",
      "tensor([ 21,  56,  92,  88, 117])\n",
      "preds is [ 21  56  25  88 117]\n",
      "tensor([124,  10,  37,  96,  73])\n",
      "preds is [124  42  37 124  73]\n",
      "tensor([63, 94, 52, 68, 43])\n",
      "preds is [45 94 62 68 43]\n",
      "tensor([ 2, 12, 19, 42,  9])\n",
      "preds is [  2 110  19 107   9]\n",
      "tensor([ 71,   4, 126, 130,  49])\n",
      "preds is [121   4 126  72  49]\n",
      "tensor([  5,   3, 104,  32,  33])\n",
      "preds is [122  66 104  32  33]\n",
      "tensor([106,  79, 102,  91,  86])\n",
      "preds is [106  79  39  91  86]\n",
      "tensor([123,  51,   2, 132, 108])\n",
      "preds is [123  51   2 132 108]\n",
      "tensor([127,  57,  94,  22,  31])\n",
      "preds is [127  57  94  22  31]\n",
      "tensor([ 65, 105,  90,  69,  31])\n",
      "preds is [ 65 105  90 101  31]\n",
      "tensor([59,  6, 78, 16, 60])\n",
      "preds is [59  6 94 16 60]\n",
      "tensor([ 11,  38, 125,  65,  10])\n",
      "preds is [ 11  38 125  65  10]\n",
      "tensor([ 36,  75, 108,  11,  34])\n",
      "preds is [ 36  75 108  11  65]\n",
      "tensor([ 16, 102,  60, 103,  75])\n",
      "preds is [ 16 102  60 103  75]\n",
      "tensor([55, 69, 41, 11, 13])\n",
      "preds is [113 101  41  11  13]\n",
      "tensor([55, 86, 23, 97, 41])\n",
      "preds is [69 86 23 97 41]\n",
      "tensor([ 5, 50, 28,  2, 44])\n",
      "preds is [  5 105  28   2 117]\n",
      "tensor([129, 111,  42,  32,  95])\n",
      "preds is [ 84 111  42  32  95]\n",
      "tensor([ 14,  87,  26, 124, 107])\n",
      "preds is [ 14  87  26 124 107]\n",
      "tensor([107,  46,  44,  64,  34])\n",
      "preds is [109  46  44  79  34]\n",
      "tensor([ 87,  92, 114,  64,  73])\n",
      "preds is [ 87 124 114  64  25]\n",
      "tensor([  6,  22,  81,  41, 114])\n",
      "preds is [  6  22  99  41 114]\n",
      "tensor([123,  72,  51,  82,  51])\n",
      "preds is [123 104  51  82 129]\n",
      "tensor([ 14,  27,  13,  99, 113])\n",
      "preds is [ 14  27  13 103 113]\n",
      "tensor([ 67,  44,  22, 126,  40])\n",
      "preds is [ 67  44  22 126  40]\n",
      "tensor([ 8, 26, 51, 81, 57])\n",
      "preds is [  8  26  51 124  57]\n",
      "tensor([ 32,  10, 127,  20, 102])\n",
      "preds is [ 32  42 127  20  43]\n",
      "tensor([64, 70, 39, 28,  5])\n",
      "preds is [ 64 108  39  28   5]\n",
      "tensor([61, 44, 34, 14, 15])\n",
      "preds is [ 61 117  34  14  55]\n",
      "tensor([114,  53,  85,  18, 120])\n",
      "preds is [114  53  85  18 120]\n",
      "tensor([119,  32,  86,  94,  54])\n",
      "preds is [119  32  86  78  54]\n",
      "tensor([70, 28, 88, 88, 31])\n",
      "preds is [70 28 88 88 31]\n",
      "tensor([120,   6,  43,  18, 125])\n",
      "preds is [120   6  43  18 125]\n",
      "tensor([84,  0, 80, 88, 45])\n",
      "preds is [84  0 89 88 76]\n",
      "tensor([  2, 111,   7,  87,  26])\n",
      "preds is [  2 111   7  87  26]\n",
      "tensor([ 39,  60,  94,  53, 101])\n",
      "preds is [ 39  60  94  53 101]\n",
      "tensor([ 71,  85, 129,  75,  82])\n",
      "preds is [ 71  85 129  75  82]\n",
      "tensor([ 41, 118,  14,  56,  89])\n",
      "preds is [ 41 118  14  56  89]\n",
      "tensor([ 86,  27,  71,  90, 118])\n",
      "preds is [ 86 121 121  90 118]\n",
      "tensor([102,  42,  87,  86,  29])\n",
      "preds is [102  42  87  86  29]\n",
      "tensor([18, 30, 70, 40, 45])\n",
      "preds is [18 30 70 40 45]\n",
      "tensor([ 37,   7, 106, 113,  62])\n",
      "preds is [ 37   7 106 113  62]\n",
      "tensor([128,  21,  74,  59,  58])\n",
      "preds is [128  21 118  59  58]\n",
      "tensor([128,  22,  48,  59,   7])\n",
      "preds is [128  22  48  59   7]\n",
      "tensor([13, 63, 55,  3, 96])\n",
      "preds is [13 76 55  4  2]\n",
      "tensor([ 4, 96, 40, 15, 81])\n",
      "preds is [ 4 96 33 15 81]\n",
      "tensor([72, 14, 52, 93, 95])\n",
      "preds is [62 14 63 93 95]\n",
      "tensor([31, 64, 43, 63, 90])\n",
      "preds is [31 64 43 63 90]\n",
      "tensor([71, 24, 67,  4, 56])\n",
      "preds is [71 24 67  4 56]\n",
      "tensor([ 45, 119,  76,  35,  62])\n",
      "preds is [ 45 119  76  35  62]\n",
      "tensor([ 18,   6, 114,  59,  22])\n",
      "preds is [ 18   6 114  59  22]\n",
      "tensor([ 24, 105,  78,  62,  69])\n",
      "preds is [ 24 105  78  62  69]\n",
      "tensor([128,  49,  14, 117,  71])\n",
      "preds is [ 75  59  14 117  71]\n",
      "tensor([ 43, 122,  26,  11,  78])\n",
      "preds is [ 43 122  26  11  78]\n",
      "tensor([68, 89, 95, 48, 60])\n",
      "preds is [ 68  89  46 123  62]\n",
      "tensor([ 69,  40, 128,  87, 102])\n",
      "preds is [ 69  40 128 123  40]\n",
      "tensor([ 10, 117,  16,  78,  47])\n",
      "preds is [ 10 117  16  78  47]\n",
      "tensor([18, 21, 40, 88, 89])\n",
      "preds is [18 21 40 88 89]\n",
      "tensor([ 17,  38,  72, 100,  88])\n",
      "preds is [ 17  38 130 100  88]\n",
      "tensor([ 31, 112, 105,  67,  90])\n",
      "preds is [ 31 112 105 105  90]\n",
      "tensor([125,   3,  35,   7, 106])\n",
      "preds is [125  80  35   7 106]\n",
      "tensor([123, 126,  86,  66,  98])\n",
      "preds is [123 126  86  66  98]\n",
      "tensor([57, 94, 63, 47, 12])\n",
      "preds is [57 78 45 47 12]\n",
      "tensor([ 7, 66, 10, 55, 35])\n",
      "preds is [ 7 66 66 55 35]\n",
      "tensor([100,  70,  44,  27,  23])\n",
      "preds is [100  70  44  27  23]\n",
      "tensor([106,  85,   5,  13,  75])\n",
      "preds is [106  85   5  13  75]\n",
      "tensor([82, 53, 43, 50, 85])\n",
      "preds is [82 53 43 50 85]\n",
      "tensor([ 28,  19, 112,   9,  75])\n",
      "preds is [ 28  19 112  94  75]\n",
      "tensor([56, 73, 20, 73, 11])\n",
      "preds is [ 56  92  20  73 111]\n",
      "tensor([ 80,   8,  40,  83, 126])\n",
      "preds is [ 80  87  43 117 132]\n",
      "tensor([ 83, 113,  23,  40,  59])\n",
      "preds is [ 83 113  23  40  59]\n",
      "tensor([ 61,  25,   8, 124,  54])\n",
      "preds is [ 61  25  87 124  54]\n",
      "tensor([ 34,  25, 115,  11,  77])\n",
      "preds is [ 67  25 127  11  80]\n",
      "tensor([118,  25,  62,  70,  49])\n",
      "preds is [118  73  62  70  49]\n",
      "tensor([40, 72, 53, 58, 53])\n",
      "preds is [ 40 130  53  58  53]\n",
      "tensor([114, 131,   5,  24,  50])\n",
      "preds is [114 131   5  24  50]\n",
      "tensor([23, 29, 10, 89, 46])\n",
      "preds is [23 29 10 89 46]\n",
      "tensor([ 89, 111,  23,  39, 112])\n",
      "preds is [ 89 111  23  39 112]\n",
      "tensor([84, 80, 83,  1, 16])\n",
      "preds is [129  80   3   1  16]\n",
      "tensor([66, 60, 47, 65,  1])\n",
      "preds is [ 66  65 122  65   1]\n",
      "tensor([67, 15, 37, 46, 38])\n",
      "preds is [67 15 37 46 38]\n",
      "tensor([ 60, 122,  41, 112,  16])\n",
      "preds is [ 62 122  41 112  16]\n",
      "tensor([ 35,  42, 113,  19,  36])\n",
      "preds is [ 35  42 113  19  36]\n",
      "tensor([ 47,  83, 129, 100,  19])\n",
      "preds is [ 47  83 129 100  19]\n",
      "tensor([30, 38, 55, 42, 52])\n",
      "preds is [30 38 69 66 60]\n",
      "tensor([102,   0,  59,  63,  55])\n",
      "preds is [102   0  59  63 103]\n",
      "tensor([ 26,  99, 107, 128,  41])\n",
      "preds is [ 26  99  42 128 110]\n",
      "tensor([ 92, 130,  77, 114,  66])\n",
      "preds is [ 73 130  77 114  66]\n",
      "tensor([51, 17, 97, 41,  9])\n",
      "preds is [51 17 97 41  9]\n",
      "tensor([ 33,  54, 103,   3,  98])\n",
      "preds is [ 33  54 103   3  98]\n",
      "tensor([ 55,  19,  87,  20, 115])\n",
      "preds is [ 55  19  87 124 115]\n",
      "tensor([ 75, 114, 110,  14,  37])\n",
      "preds is [ 75 114 110  14  37]\n",
      "tensor([131,  62,  17,  29, 119])\n",
      "preds is [131  62  17  29 119]\n",
      "tensor([  4, 122,  13,   4,  93])\n",
      "preds is [  4 122  13   4  93]\n",
      "tensor([ 30,  61, 111,   2,  77])\n",
      "preds is [ 30  61 111   2  77]\n",
      "tensor([ 21,  27,  26, 127,   9])\n",
      "preds is [ 21  27  26 127   9]\n",
      "tensor([ 31, 108,  15,   8, 121])\n",
      "preds is [ 31 108  15  87 121]\n",
      "tensor([ 54, 109,  79,  38,  11])\n",
      "preds is [ 87 109 121  38  11]\n",
      "tensor([121, 104,  54,  91,  74])\n",
      "preds is [ 71 104  54  91  74]\n",
      "tensor([38, 28, 65, 33, 86])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds is [38 28 34 33 86]\n",
      "tensor([ 23,   7,  26, 124, 115])\n",
      "preds is [ 23   7  26 124 115]\n",
      "tensor([ 76,  33, 118,  16, 110])\n",
      "preds is [ 76  33 118  16 110]\n",
      "tensor([110,  53,  25,  99,  74])\n",
      "preds is [110  53  25  99 113]\n",
      "tensor([100,  90,  15,  12, 105])\n",
      "preds is [100  90  15  12 105]\n",
      "tensor([ 82,  47,  70, 127,   0])\n",
      "preds is [ 82 114  70 127   0]\n",
      "tensor([77, 31, 74, 69,  1])\n",
      "preds is [120  31  74 101  61]\n",
      "tensor([ 58,  39,  36,  28, 119])\n",
      "preds is [ 58  39  36  28 119]\n",
      "tensor([ 91,  76,  95, 104,  43])\n",
      "preds is [ 91  76  95 104  40]\n",
      "tensor([ 0, 17, 86, 58, 43])\n",
      "preds is [98 17 86 69  7]\n",
      "tensor([13, 67, 97, 39, 79])\n",
      "preds is [13 67 97 39 79]\n",
      "tensor([  4,  19,  41, 109,  15])\n",
      "preds is [  4  19  41 117  15]\n",
      "tensor([ 70,  48,  37,  93, 111])\n",
      "preds is [ 70  48  37  93 111]\n",
      "tensor([ 48,  46,  39, 108, 117])\n",
      "preds is [ 48  46  39 108 117]\n",
      "tensor([117,  62, 116,  28, 103])\n",
      "preds is [117  62 116  28 103]\n",
      "tensor([56, 97, 74, 49,  5])\n",
      "preds is [56 97 88 49  5]\n",
      "tensor([119,   6, 111, 122,  15])\n",
      "preds is [119   6 111 114  15]\n",
      "tensor([ 40,  81, 129,  57,  85])\n",
      "preds is [ 40  99 129  57  85]\n",
      "tensor([130,  80, 114,  73,  23])\n",
      "preds is [130  69 114  73  23]\n",
      "tensor([ 80,  33,  16, 112,  67])\n",
      "preds is [ 80  33  16 112  67]\n",
      "tensor([60, 57, 35, 29, 43])\n",
      "preds is [60 57 35 29 43]\n",
      "tensor([ 20,  98,  28,  50, 117])\n",
      "preds is [ 20  81  28  50 117]\n",
      "tensor([116,  90,  58,  22, 116])\n",
      "preds is [116  90  58  22 116]\n",
      "tensor([106, 115,   3,  54,  56])\n",
      "preds is [106 115   3  54  56]\n",
      "tensor([12, 44, 45, 19, 21])\n",
      "preds is [126  44  45  19  21]\n",
      "tensor([83, 36, 68,  6, 20])\n",
      "preds is [83 36 68  6 20]\n",
      "tensor([38, 24, 61, 45, 49])\n",
      "preds is [38 24 61 45 59]\n",
      "tensor([52,  1, 49, 47, 29])\n",
      "preds is [52  1 49 47 29]\n",
      "tensor([ 95, 117,  11,  97,  78])\n",
      "preds is [ 95 117  36  97  94]\n",
      "tensor([131,  79,  61,  53,  14])\n",
      "preds is [131  79  61  53  14]\n",
      "tensor([16, 96, 56, 30, 93])\n",
      "preds is [16  2 56 30 93]\n",
      "tensor([120,  54,  37,  80,  76])\n",
      "preds is [120  54  37  80  76]\n",
      "tensor([68, 20, 88,  2, 29])\n",
      "preds is [68 20 16  2 29]\n",
      "tensor([ 7, 11, 89, 56, 39])\n",
      "preds is [ 7 11 89 56 39]\n",
      "tensor([51, 10, 33, 78, 50])\n",
      "preds is [51 10 33 78 50]\n",
      "tensor([123,  91,  96, 110,  67])\n",
      "preds is [123  91 124 110  67]\n",
      "tensor([81])\n",
      "preds is 99\n",
      "Acc: 83.61%\n",
      "tensor(0.8361, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "testacc=test_acc(iter(dataloaders['test']), predictor)\n",
    "print(testacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
