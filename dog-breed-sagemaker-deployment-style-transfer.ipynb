{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define imports\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "#import PIL\n",
    "import os, random\n",
    "\n",
    "from glob import glob\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from IPython.display import display, Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "\n",
    "\n",
    "import copy\n",
    "#import cv2                \n",
    "\n",
    "from io import open\n",
    "import json\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, os.path, random\n",
    "from PIL import Image\n",
    "import requests\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# my imports\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join, abspath\n",
    "from style_transfer.stylize import transfer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All images are resized to 224x224 and normalized\n",
    "# Only training images receive further augmentation\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogImages_style_transfer/valid\n",
      "{'train': 59800, 'valid': 835, 'test': 836}\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'dogImages_style_transfer'\n",
    "print(os.path.join(data_dir, 'valid'))\n",
    "\n",
    "\n",
    "# we create some dictionaries\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'valid', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=5,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'valid', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid', 'test']}\n",
    "print(dataset_sizes)\n",
    "class_names = image_datasets['train'].classes\n",
    "n_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create an S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# this is the S3 data_dir name\n",
    "data_dir = 'dogImages'\n",
    "train_dir = 'train'\n",
    "\n",
    "# set prefix, a descriptive name for a directory  \n",
    "prefix = 'capstone-project'\n",
    "\n",
    "# upload data for the first time; otherwise use the second expression (because the S3 upload takes some time)\n",
    "#train_location = sagemaker_session.upload_data(os.path.join(data_dir), key_prefix=prefix)\n",
    "train_location = 's3://{}/{}/'.format(bucket, prefix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your import and estimator code, here\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix)\n",
    "\n",
    "# note: this PyTorch estimator is specified with code that only\n",
    "# uses the style transferred pictures, but no imgaug preprocessing!\n",
    "source_dir = 'source_pytorch_style_transfer'\n",
    "\n",
    "# instantiate a pytorch estimator\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                    source_dir=source_dir,\n",
    "                    role=role,\n",
    "                    framework_version='1.1.0',\n",
    "                    train_instance_count=1,\n",
    "                    #train_instance_type='ml.c4.xlarge',\n",
    "                    train_instance_type='ml.p2.xlarge',\n",
    "                    output_path=output_path,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    hyperparameters={\n",
    "                        'epochs': 10\n",
    "                    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-06 07:17:23 Starting - Starting the training job...\n",
      "2019-08-06 07:17:25 Starting - Launching requested ML instances......\n",
      "2019-08-06 07:18:24 Starting - Preparing the instances for training......\n",
      "2019-08-06 07:19:30 Downloading - Downloading input data................................................\n",
      "2019-08-06 07:27:52 Training - Downloading the training image..\n",
      "\u001b[31mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[31mbash: no job control in this shell\u001b[0m\n",
      "\u001b[31m2019-08-06 07:28:06,957 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[31m2019-08-06 07:28:06,981 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[31m2019-08-06 07:28:06,982 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[31m2019-08-06 07:28:07,231 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2019-08-06 07:28:07,231 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2019-08-06 07:28:07,232 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2019-08-06 07:28:07,232 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mCollecting pillow==5.4.1 (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[31m  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\u001b[0m\n",
      "\u001b[31mCollecting imgaug==0.2.9 (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/17/a9/36de8c0e1ffb2d86f871cac60e5caa910cbbdb5f4741df5ef856c47f4445/imgaug-0.2.9-py2.py3-none-any.whl (753kB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (4.0.1.24)\u001b[0m\n",
      "\u001b[31mCollecting imageio (from imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/af/0a/943c965d372dae0b1f1482677d29030ab834351a61a9a632fd62f27f1523/imageio-2.5.0-py3-none-any.whl (3.3MB)\u001b[0m\n",
      "\u001b[31mCollecting scikit-image>=0.11.0 (from imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/ab/674e168bf7d0bc597218b3bec858d02c23fbac9ec1fec9cad878c6cee95f/scikit_image-0.15.0-cp36-cp36m-manylinux1_x86_64.whl (26.3MB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (1.3.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (1.16.4)\u001b[0m\n",
      "\u001b[31mCollecting Shapely (from imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/38/b6/b53f19062afd49bb5abd049aeed36f13bf8d57ef8f3fa07a5203531a0252/Shapely-1.6.4.post2-cp36-cp36m-manylinux1_x86_64.whl (1.5MB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (1.12.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (3.1.0)\u001b[0m\n",
      "\u001b[31mCollecting PyWavelets>=0.4.0 (from scikit-image>=0.11.0->imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/cd/528dba0b474b08f6f9a3a5e1b4bb23d8e33ed5d9f0e321cc967c2607df05/PyWavelets-1.0.3-cp36-cp36m-manylinux1_x86_64.whl (4.4MB)\u001b[0m\n",
      "\u001b[31mCollecting networkx>=2.0 (from scikit-image>=0.11.0->imgaug==0.2.9->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[31m  Downloading https://files.pythonhosted.org/packages/85/08/f20aef11d4c343b557e5de6b9548761811eb16e438cee3d32b1c66c8566b/networkx-2.3.zip (1.7MB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (2.4.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (2.8.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (0.10.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (1.1.0)\u001b[0m\n",
      "\u001b[31mCollecting decorator>=4.3.0 (from networkx>=2.0->scikit-image>=0.11.0->imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/5f/88/0075e461560a1e750a0dcbf77f1d9de775028c37a19a346a6c565a257399/decorator-4.4.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (41.0.1)\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: train, networkx\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-19tz_wfj/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "  Running setup.py bdist_wheel for networkx: started\u001b[0m\n",
      "\u001b[31m  Running setup.py bdist_wheel for networkx: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/de/63/64/3699be2a9d0ccdb37c7f16329acf3863fd76eda58c39c737af\u001b[0m\n",
      "\n",
      "2019-08-06 07:28:06 Training - Training image download completed. Training in progress.\u001b[31mSuccessfully built train networkx\u001b[0m\n",
      "\u001b[31msagemaker-pytorch-container 1.2 has requirement Pillow==6.0.0, but you'll have pillow 5.4.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mInstalling collected packages: pillow, imageio, PyWavelets, decorator, networkx, scikit-image, Shapely, imgaug, train\n",
      "  Found existing installation: Pillow 6.0.0\n",
      "    Uninstalling Pillow-6.0.0:\n",
      "      Successfully uninstalled Pillow-6.0.0\u001b[0m\n",
      "\u001b[31mSuccessfully installed PyWavelets-1.0.3 Shapely-1.6.4.post2 decorator-4.4.0 imageio-2.5.0 imgaug-0.2.9 networkx-2.3 pillow-5.4.1 scikit-image-0.15.0 train-1.0.0\u001b[0m\n",
      "\u001b[31mYou are using pip version 18.1, however version 19.2.1 is available.\u001b[0m\n",
      "\u001b[31mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31m2019-08-06 07:28:15,232 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2019-08-06-07-17-23-482\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-central-1-505649883860/sagemaker-pytorch-2019-08-06-07-17-23-482/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[31mSM_HPS={\"epochs\":10}\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://sagemaker-eu-central-1-505649883860/sagemaker-pytorch-2019-08-06-07-17-23-482/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2019-08-06-07-17-23-482\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-central-1-505649883860/sagemaker-pytorch-2019-08-06-07-17-23-482/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--epochs\",\"10\"]\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[31mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m train --epochs 10\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mUsing device cuda.\u001b[0m\n",
      "\u001b[31mGet train data loader.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mEpoch: 1 #011Training Loss: 3.636029 #011Validation Loss: 1.318098\u001b[0m\n",
      "\u001b[31mEpoch: 2 #011Training Loss: 2.686004 #011Validation Loss: 0.844991\u001b[0m\n",
      "\u001b[31mEpoch: 3 #011Training Loss: 2.387923 #011Validation Loss: 0.685585\u001b[0m\n",
      "\u001b[31mEpoch: 4 #011Training Loss: 2.232464 #011Validation Loss: 0.606484\u001b[0m\n",
      "\u001b[31mEpoch: 5 #011Training Loss: 2.129745 #011Validation Loss: 0.561718\u001b[0m\n",
      "\u001b[31mEpoch: 6 #011Training Loss: 2.060371 #011Validation Loss: 0.529383\u001b[0m\n",
      "\u001b[31mEpoch: 7 #011Training Loss: 2.005694 #011Validation Loss: 0.505579\u001b[0m\n",
      "\u001b[31mEpoch: 8 #011Training Loss: 1.954784 #011Validation Loss: 0.488833\u001b[0m\n",
      "\u001b[31mEpoch: 9 #011Training Loss: 1.920151 #011Validation Loss: 0.476198\u001b[0m\n",
      "\u001b[31mEpoch: 10 #011Training Loss: 1.887669 #011Validation Loss: 0.465194\u001b[0m\n",
      "\u001b[31m2019-08-06 09:12:41,527 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2019-08-06 09:12:45 Uploading - Uploading generated training model\n",
      "2019-08-06 09:14:00 Completed - Training job completed\n",
      "Billable seconds: 6871\n",
      "CPU times: user 12.9 s, sys: 626 ms, total: 13.5 s\n",
      "Wall time: 1h 56min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train your estimator on S3 training data\n",
    "estimator.fit({'train': train_location})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-eu-central-1-505649883860/capstone-project/sagemaker-pytorch-2019-08-06-07-17-23-482/output/model.tar.gz\n",
      "CPU times: user 17.6 ms, sys: 46 Âµs, total: 17.6 ms\n",
      "Wall time: 71.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# importing PyTorchModel\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "print(estimator.model_data)\n",
    "\n",
    "# Create a model from the trained estimator data\n",
    "# And point to the prediction script\n",
    "model = PyTorchModel(model_data=estimator.model_data,\n",
    "                     role = role,\n",
    "                     framework_version='1.1.0',\n",
    "                     entry_point='predict.py',\n",
    "                     source_dir=source_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "# ATTENTION: Please use the ml.t2.large instance here. Otherwise the deployment will fail because of resource constraints\n",
    "# predictor = model.deploy(initial_instance_count=1, instance_type='ml.t2.medium')\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.t2.large')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 37,  49,  35, 128,  70])\n",
      "preds is [ 37  59  35 128  70]\n",
      "tensor([70, 93, 88, 81, 56])\n",
      "preds is [70 93 88 81 56]\n",
      "tensor([38, 37, 36, 12, 35])\n",
      "preds is [ 38  37  36 126  35]\n",
      "tensor([130,  84,  23,  21,  86])\n",
      "preds is [130  84  23  21  86]\n",
      "tensor([110,  39,   8,  94, 114])\n",
      "preds is [110  39  87  94 114]\n",
      "tensor([ 16,  30,  35,  81, 101])\n",
      "preds is [ 16  30  35  81 101]\n",
      "tensor([88, 96, 83, 78, 37])\n",
      "preds is [88  2 83 94 37]\n",
      "tensor([ 57,   5,  90, 127,  77])\n",
      "preds is [ 57   5  90 127  80]\n",
      "tensor([ 34, 100,  31,  18,  65])\n",
      "preds is [ 95 100  31  18  65]\n",
      "tensor([131,  14, 126,  92,  60])\n",
      "preds is [131  14 126  25  60]\n",
      "tensor([ 34,  64,  30,  54, 124])\n",
      "preds is [ 34  64  30  54 124]\n",
      "tensor([110,  21,   3,  20,  11])\n",
      "preds is [110  21   3  20  11]\n",
      "tensor([115,  91,  32,   7,  15])\n",
      "preds is [115  91  32   7   6]\n",
      "tensor([ 67,   7,  49, 110,  96])\n",
      "preds is [ 67   7  49 110 124]\n",
      "tensor([121,   6,  87,  14, 122])\n",
      "preds is [121   6   8  14 122]\n",
      "tensor([56, 98,  4, 94, 31])\n",
      "preds is [56 98  4 78 31]\n",
      "tensor([89, 61, 29, 41, 87])\n",
      "preds is [ 89 129  29  41 123]\n",
      "tensor([  4, 103,   7,  27,  58])\n",
      "preds is [  4 103   7  61  58]\n",
      "tensor([ 23, 128,  15,   6,  13])\n",
      "preds is [ 23 128  15   6  13]\n",
      "tensor([ 59,  72, 118, 114,   0])\n",
      "preds is [ 59 130 118 114   0]\n",
      "tensor([125,  40,  71,  64,  52])\n",
      "preds is [125  40 121  79  62]\n",
      "tensor([50, 90, 39, 86, 44])\n",
      "preds is [50 90 39 86 44]\n",
      "tensor([ 60,  68,  30,  36, 112])\n",
      "preds is [ 76  68  30  36 112]\n",
      "tensor([ 57, 100,  71,   4,  74])\n",
      "preds is [100 100  71   4 113]\n",
      "tensor([116,  66,  15, 117,  13])\n",
      "preds is [116  66  15 117  42]\n",
      "tensor([ 27, 111, 115,  64,  56])\n",
      "preds is [ 27 111 115  64  56]\n",
      "tensor([ 54, 125,  80,  80,  70])\n",
      "preds is [ 54 125  80  80  70]\n",
      "tensor([15, 20, 27, 33, 64])\n",
      "preds is [15 20 27 33 64]\n",
      "tensor([107,  77,  70, 116,  85])\n",
      "preds is [ 66  77  70 116  85]\n",
      "tensor([ 72,   4,  74, 106,  47])\n",
      "preds is [ 62   4  74 106  47]\n",
      "tensor([97, 55, 94, 19, 73])\n",
      "preds is [ 97 113  94  19  92]\n",
      "tensor([ 91, 123,  11,   1,  20])\n",
      "preds is [ 91 123  11   1  20]\n",
      "tensor([34, 13, 83, 29,  8])\n",
      "preds is [34 13 83 29 87]\n",
      "tensor([ 12, 111, 119,  85, 111])\n",
      "preds is [ 12 111 119  85 111]\n",
      "tensor([45, 28, 33,  0, 98])\n",
      "preds is [45 28 33  0 81]\n",
      "tensor([69, 31, 61, 14,  5])\n",
      "preds is [101  31  61  14   5]\n",
      "tensor([ 59,  85,  12, 105,  77])\n",
      "preds is [ 59  85  12 105  77]\n",
      "tensor([ 14,  26, 121,  25,  54])\n",
      "preds is [14 26 71 25 54]\n",
      "tensor([ 35,   4, 116, 130, 117])\n",
      "preds is [ 35   4  37 130 117]\n",
      "tensor([51, 69, 66, 45, 86])\n",
      "preds is [ 51 101  66  45  86]\n",
      "tensor([114,  85,  60,   2, 102])\n",
      "preds is [114  85  60   2 102]\n",
      "tensor([ 78,  62,  27, 119,  15])\n",
      "preds is [125  62  27 119  15]\n",
      "tensor([ 89, 104,  16, 106,  69])\n",
      "preds is [ 89 104  16 106  69]\n",
      "tensor([75, 17, 29,  1,  4])\n",
      "preds is [75 17 29 52  4]\n",
      "tensor([122,  89,  60,  35,  17])\n",
      "preds is [122  89  72  35  17]\n",
      "tensor([ 42,  51,   3, 102,  60])\n",
      "preds is [ 42  62   3 102  62]\n",
      "tensor([61, 78, 16, 42, 66])\n",
      "preds is [129  94  16  42 117]\n",
      "tensor([ 4, 48, 41, 50, 39])\n",
      "preds is [  4  48  41 105  39]\n",
      "tensor([48, 24, 26, 36, 55])\n",
      "preds is [48 24 26 62 69]\n",
      "tensor([120,  89,  91, 115,  55])\n",
      "preds is [120  89  91 115  55]\n",
      "tensor([70, 97, 62, 80, 49])\n",
      "preds is [70 97 62 69 49]\n",
      "tensor([ 37, 111,  20,  36,  78])\n",
      "preds is [ 37 111  20  84  78]\n",
      "tensor([100,  31,  29, 126,   5])\n",
      "preds is [100  31  29 126   5]\n",
      "tensor([ 1, 40, 76, 69, 53])\n",
      "preds is [35 43 76 69 53]\n",
      "tensor([ 36,  43, 109,  50,  37])\n",
      "preds is [ 36  43  13  50 132]\n",
      "tensor([ 62, 114,  73,  13,  38])\n",
      "preds is [ 67 114  25  13  38]\n",
      "tensor([ 71, 103, 102,  96,  86])\n",
      "preds is [ 71 103 102   2  86]\n",
      "tensor([ 44,  43,   0, 110,  82])\n",
      "preds is [ 44  43   0 110  82]\n",
      "tensor([24, 77, 29, 61, 18])\n",
      "preds is [ 55 121  29  61  18]\n",
      "tensor([113,   4,  90, 123, 106])\n",
      "preds is [113   4  90 123 106]\n",
      "tensor([108, 112,  80,  25,  55])\n",
      "preds is [ 91 112  80  32  55]\n",
      "tensor([  9,  39,  13,   5, 129])\n",
      "preds is [  9  39  13 122 129]\n",
      "tensor([57, 54, 56, 75,  7])\n",
      "preds is [ 57 123  56  75   7]\n",
      "tensor([ 93,  10,  28, 108,  32])\n",
      "preds is [ 93  10  28 108  32]\n",
      "tensor([ 40, 117,  63, 114,  26])\n",
      "preds is [ 40 117  63 114  26]\n",
      "tensor([ 10,  97,   2, 107,  38])\n",
      "preds is [ 10  97   2 107  38]\n",
      "tensor([ 88, 111, 111,  55,  53])\n",
      "preds is [ 88 111 111  85  53]\n",
      "tensor([ 6, 82, 33, 40, 47])\n",
      "preds is [ 6 82 33 40 47]\n",
      "tensor([ 89,  53,  59, 104, 105])\n",
      "preds is [ 89  53  59 104 105]\n",
      "tensor([ 44,  56, 119,  38,  57])\n",
      "preds is [ 44  56 119  38  57]\n",
      "tensor([ 10,  50, 104,  17,  22])\n",
      "preds is [ 10  50 104  17  22]\n",
      "tensor([ 67,  92,  23,  21, 103])\n",
      "preds is [ 67  92  23  21 103]\n",
      "tensor([129,  38,  83,  39,  46])\n",
      "preds is [129  38  83  39  46]\n",
      "tensor([ 45, 122,  96,  19, 113])\n",
      "preds is [ 45 114  96  19 113]\n",
      "tensor([125, 131, 105,  73, 112])\n",
      "preds is [125 131 105  73 112]\n",
      "tensor([ 18,  76, 123,  58,   1])\n",
      "preds is [ 18  76 123  69   1]\n",
      "tensor([128,  28, 126,  16, 110])\n",
      "preds is [128  28 126  16 110]\n",
      "tensor([85, 79, 75, 92, 65])\n",
      "preds is [85 79 75 92 65]\n",
      "tensor([71,  5, 26, 19, 42])\n",
      "preds is [71  5 26 19 66]\n",
      "tensor([ 66,  15,  70, 132,  14])\n",
      "preds is [ 83  15 108 132  14]\n",
      "tensor([ 46, 109, 123, 117,  74])\n",
      "preds is [ 46 109 123 117  74]\n",
      "tensor([52, 70, 19, 56, 81])\n",
      "preds is [ 63  70  19  56 100]\n",
      "tensor([114,  68, 112,  59,  79])\n",
      "preds is [114  68 112  59  79]\n",
      "tensor([ 98, 126,  79,  44,  24])\n",
      "preds is [ 98 132  79 117  24]\n",
      "tensor([ 81, 124,  99, 117,  21])\n",
      "preds is [ 81 124  99 117  21]\n",
      "tensor([127,  59,  72,  11,  91])\n",
      "preds is [127  59  36  11  91]\n",
      "tensor([ 43, 122,  79,  61,  10])\n",
      "preds is [ 43 122  79  61  10]\n",
      "tensor([ 53, 129,  18, 113,   0])\n",
      "preds is [ 53  84  18 113   0]\n",
      "tensor([116,  46, 128,  28,  87])\n",
      "preds is [116  46  50  28  87]\n",
      "tensor([  7, 108,  23,  62,   6])\n",
      "preds is [  7 108  23  62   6]\n",
      "tensor([100,  83, 115,  19,   9])\n",
      "preds is [100 117 115  19   9]\n",
      "tensor([38, 40, 49, 10, 84])\n",
      "preds is [ 38  33  49  10 129]\n",
      "tensor([ 42,  88,   3, 121, 105])\n",
      "preds is [ 42  88   3  36 105]\n",
      "tensor([ 95,  38,  33,  19, 127])\n",
      "preds is [ 39  38  33  19 127]\n",
      "tensor([132,  78, 109, 124,  41])\n",
      "preds is [132  78 117 124  41]\n",
      "tensor([ 5, 48,  1, 95, 54])\n",
      "preds is [ 5 48  1 95 54]\n",
      "tensor([ 75,   2,  76, 118,  33])\n",
      "preds is [ 75   2  76 118  33]\n",
      "tensor([  7,  63,  74, 123, 108])\n",
      "preds is [  7  63 118 123 108]\n",
      "tensor([105,  93,  50,  31, 113])\n",
      "preds is [105  93  50  31 113]\n",
      "tensor([25,  9,  2, 79, 26])\n",
      "preds is [25 94  2 79 26]\n",
      "tensor([  3,  53, 102,  11,  26])\n",
      "preds is [ 3 53 40 11 26]\n",
      "tensor([69, 10, 31, 86, 28])\n",
      "preds is [69 42 31 86 28]\n",
      "tensor([ 33,  35, 104,  45,  71])\n",
      "preds is [ 33  35 104  45  95]\n",
      "tensor([89, 86, 41, 41,  8])\n",
      "preds is [119  86 110  41  34]\n",
      "tensor([ 20, 121,  20,   4,  40])\n",
      "preds is [20 71 20  4 40]\n",
      "tensor([ 51, 119,  43,   6,  30])\n",
      "preds is [ 51 119  43   6  30]\n",
      "tensor([10, 55, 51, 34,  9])\n",
      "preds is [ 42 118  51  65   9]\n",
      "tensor([ 41, 101, 103,  57,  96])\n",
      "preds is [ 41 101 103  57 124]\n",
      "tensor([ 95,  91, 126,  37,  90])\n",
      "preds is [ 95  91 132  37  90]\n",
      "tensor([ 88, 118,  31, 102,   1])\n",
      "preds is [ 16 118  31 102  61]\n",
      "tensor([ 11, 124,  63,  58,  33])\n",
      "preds is [ 11 124  45  69  33]\n",
      "tensor([103,  90,  94, 106,  67])\n",
      "preds is [103  90  78 106  67]\n",
      "tensor([ 75,  17,  60,  28, 107])\n",
      "preds is [ 75  17  60  28 109]\n",
      "tensor([13, 87, 38,  6, 47])\n",
      "preds is [13 87 38 95 47]\n",
      "tensor([ 45, 106,  16,  53,  67])\n",
      "preds is [ 45 106  16  53  67]\n",
      "tensor([58, 34, 46, 32, 17])\n",
      "preds is [58 34 46 73 17]\n",
      "tensor([ 35, 123,  55, 117,  71])\n",
      "preds is [ 35 123  60 117 121]\n",
      "tensor([116,  67,  95,  21,  41])\n",
      "preds is [116  67  95  20  41]\n",
      "tensor([ 48, 102,  22,   2,  97])\n",
      "preds is [132  39  22   2  97]\n",
      "tensor([35, 68, 21, 68, 51])\n",
      "preds is [35 68 21 68 51]\n",
      "tensor([ 70,  46,  56,   2, 108])\n",
      "preds is [ 70  46  56   2 108]\n",
      "tensor([40, 14, 46,  7, 23])\n",
      "preds is [40 14 46  7 23]\n",
      "tensor([33, 44, 45, 25, 82])\n",
      "preds is [ 33 117  76  73  82]\n",
      "tensor([60, 14, 94, 56,  5])\n",
      "preds is [60 14 78 56  5]\n",
      "tensor([82, 50,  3, 76, 42])\n",
      "preds is [ 82  50   3  76 107]\n",
      "tensor([80, 63, 65, 26, 22])\n",
      "preds is [80 45 65 26 22]\n",
      "tensor([105, 106,   6,  84,  28])\n",
      "preds is [105 106   6 129  28]\n",
      "tensor([118,   8,  63,  61,  74])\n",
      "preds is [ 16   8  63  61 126]\n",
      "tensor([ 83, 112,  16,  40,  50])\n",
      "preds is [117 112  16  40  50]\n",
      "tensor([ 11,  55,   1,  43, 120])\n",
      "preds is [ 11  55   1  43 120]\n",
      "tensor([96, 41, 28, 77, 87])\n",
      "preds is [96 41 28 77 87]\n",
      "tensor([55,  0, 25, 86, 14])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds is [ 55   0 124  86  14]\n",
      "tensor([14, 47, 30, 99, 95])\n",
      "preds is [ 14 107  30 103  46]\n",
      "tensor([ 22, 111,  48, 114, 100])\n",
      "preds is [ 22 111  48 114 100]\n",
      "tensor([ 62,  88,  44,  57, 119])\n",
      "preds is [ 62  88  44  57 119]\n",
      "tensor([ 22,  78, 100,   0, 129])\n",
      "preds is [ 22  78 100  98 129]\n",
      "tensor([ 15,  80,  67, 131,  12])\n",
      "preds is [ 15  80  67 131  12]\n",
      "tensor([22, 17, 22, 47, 82])\n",
      "preds is [22 17 22 47 82]\n",
      "tensor([73, 11, 16, 75, 28])\n",
      "preds is [73 11 16 75 28]\n",
      "tensor([59, 93, 52, 49, 69])\n",
      "preds is [59 93 52 49 69]\n",
      "tensor([97,  3, 45, 23,  0])\n",
      "preds is [97 42 45 23  0]\n",
      "tensor([53, 57, 29,  3, 83])\n",
      "preds is [ 53  57  29   4 114]\n",
      "tensor([54, 78, 52, 67, 68])\n",
      "preds is [54 94 52 67 68]\n",
      "tensor([ 54, 116,  75,  13,  52])\n",
      "preds is [ 54 116  75  13 129]\n",
      "tensor([56, 58,  3, 65, 81])\n",
      "preds is [56 69  3 65 81]\n",
      "tensor([ 48,  84,  86,  31, 132])\n",
      "preds is [123  84  86  31 132]\n",
      "tensor([ 64,  94,  30, 122, 117])\n",
      "preds is [ 64  94  53 122 117]\n",
      "tensor([81, 89, 45,  9, 99])\n",
      "preds is [124  89  76   9  99]\n",
      "tensor([ 85,  98, 130,  99, 128])\n",
      "preds is [ 85  98  72  99 128]\n",
      "tensor([101,  45,  13, 102,  62])\n",
      "preds is [101  45  13 102  62]\n",
      "tensor([ 72, 132,  24,  19,  10])\n",
      "preds is [130 132  24  19 117]\n",
      "tensor([49, 11, 12, 37, 80])\n",
      "preds is [59 11 12 37 80]\n",
      "tensor([ 4, 23, 76, 18, 75])\n",
      "preds is [ 4 23 76 18 75]\n",
      "tensor([73, 19, 40, 88, 93])\n",
      "preds is [73 19 40 88 93]\n",
      "tensor([ 89,  20,  38, 109,  15])\n",
      "preds is [ 89  25  38 117  15]\n",
      "tensor([ 22, 120,  58,  42,  13])\n",
      "preds is [ 22 120  69  95  13]\n",
      "tensor([47, 36, 43, 16, 90])\n",
      "preds is [114  36  43  16  90]\n",
      "tensor([39, 60, 81, 50, 98])\n",
      "preds is [39 62 99 50 98]\n",
      "tensor([29, 59, 51, 72, 20])\n",
      "preds is [29 59 51 73 20]\n",
      "tensor([ 32,  32, 114, 129,  85])\n",
      "preds is [ 32  32 114  84  85]\n",
      "tensor([81, 47, 34, 14, 30])\n",
      "preds is [ 99 122  34  14  30]\n",
      "tensor([59, 10, 90,  0, 82])\n",
      "preds is [59 10 90  0 82]\n",
      "tensor([128,  18,  12,  68,   7])\n",
      "preds is [ 75  18 110  68   7]\n",
      "tensor([43, 39, 92, 68, 43])\n",
      "preds is [40 39 73 68  7]\n",
      "tensor([ 1,  9, 23, 17, 28])\n",
      "preds is [ 1  9 23 17 28]\n",
      "tensor([ 11, 127,  67,  62,  52])\n",
      "preds is [ 28 127 105  62  75]\n",
      "tensor([26, 78, 87,  5, 46])\n",
      "preds is [26 94 87  5 46]\n",
      "tensor([44])\n",
      "preds is 44\n",
      "Acc: 81.58%\n",
      "tensor(0.8158, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "def test_acc(test_set, predictor):\n",
    "    ''' \n",
    "    This method calculates our accuracy metric. For this, it will send \n",
    "    batches of data to the endpoint and receive the predictions\n",
    "    '''\n",
    "    test_acc = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in test_set:\n",
    "        print(labels)\n",
    "        test_y_preds = predictor.predict(inputs)\n",
    "\n",
    "        _, preds_tensor = torch.max(torch.from_numpy(test_y_preds), 1)\n",
    "        preds = np.squeeze(preds_tensor.numpy()) if not use_cuda else np.squeeze(preds_tensor.cpu().numpy())\n",
    "\n",
    "        print(f\"preds is {preds}\")\n",
    "    \n",
    "        # compare the batch of predictions with the ground truth of labels\n",
    "        running_corrects += torch.sum(torch.from_numpy(preds) == labels)\n",
    "\n",
    "    test_acc = running_corrects.double() / len(test_set.dataset)\n",
    "\n",
    "    print('Acc: {:.2f}%'.format(test_acc*100))\n",
    "\n",
    "    return test_acc\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "testacc=test_acc(iter(dataloaders['test']), predictor)\n",
    "print(testacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we want to see how our baseline model keeps up. For this, we first need to upload the original dogImages (no style transferred images includes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# this is the S3 data_dir name\n",
    "data_dir = 'dogImages'\n",
    "\n",
    "# set prefix, a descriptive name for a directory  \n",
    "prefix = 'capstone-project-orig-data'\n",
    "\n",
    "# upload data for the first time; otherwise use the second expression (because the S3 upload takes some time)\n",
    "#train_location_orig_data = sagemaker_session.upload_data(os.path.join(data_dir), key_prefix=prefix)\n",
    "train_location_orig_data = 's3://{}/{}/'.format(bucket, prefix) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimator itself and the deployment is exactly the same. We only change the `source_dir`, that specifies our `train` and `predict` file. In case of our baseline we want to keep everything as simple as possible - that is why there is no advanced image augmenting included with the `imgaug` library. For more details have a look at `source_pytorch_style_transfer/train.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your import and estimator code, here\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix)\n",
    "\n",
    "# note: this PyTorch estimator is specified with code that only\n",
    "# uses the style transferred pictures, but no imgaug preprocessing!\n",
    "source_dir = 'source_pytorch_style_transfer'\n",
    "\n",
    "# instantiate a pytorch estimator\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                    source_dir=source_dir,\n",
    "                    role=role,\n",
    "                    framework_version='1.1.0',\n",
    "                    train_instance_count=1,\n",
    "                    #train_instance_type='ml.c4.xlarge',\n",
    "                    train_instance_type='ml.p2.xlarge',\n",
    "                    output_path=output_path,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    hyperparameters={\n",
    "                        'epochs': 10\n",
    "                    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-06 06:15:31 Starting - Starting the training job...\n",
      "2019-08-06 06:15:34 Starting - Launching requested ML instances......\n",
      "2019-08-06 06:16:32 Starting - Preparing the instances for training......\n",
      "2019-08-06 06:17:48 Downloading - Downloading input data.........\n",
      "2019-08-06 06:19:28 Training - Downloading the training image..\n",
      "\n",
      "2019-08-06 06:19:46 Training - Training image download completed. Training in progress.\u001b[31mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[31mbash: no job control in this shell\u001b[0m\n",
      "\u001b[31m2019-08-06 06:19:48,128 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[31m2019-08-06 06:19:48,153 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[31m2019-08-06 06:19:48,460 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[31m2019-08-06 06:19:48,740 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2019-08-06 06:19:48,740 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2019-08-06 06:19:48,740 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2019-08-06 06:19:48,741 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mCollecting pillow==5.4.1 (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\u001b[0m\n",
      "\u001b[31mCollecting imgaug==0.2.9 (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/17/a9/36de8c0e1ffb2d86f871cac60e5caa910cbbdb5f4741df5ef856c47f4445/imgaug-0.2.9-py2.py3-none-any.whl (753kB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (1.12.0)\u001b[0m\n",
      "\u001b[31mCollecting scikit-image>=0.11.0 (from imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/ab/674e168bf7d0bc597218b3bec858d02c23fbac9ec1fec9cad878c6cee95f/scikit_image-0.15.0-cp36-cp36m-manylinux1_x86_64.whl (26.3MB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (4.0.1.24)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (1.3.0)\u001b[0m\n",
      "\u001b[31mCollecting Shapely (from imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/38/b6/b53f19062afd49bb5abd049aeed36f13bf8d57ef8f3fa07a5203531a0252/Shapely-1.6.4.post2-cp36-cp36m-manylinux1_x86_64.whl (1.5MB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (3.1.0)\u001b[0m\n",
      "\u001b[31mCollecting imageio (from imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/af/0a/943c965d372dae0b1f1482677d29030ab834351a61a9a632fd62f27f1523/imageio-2.5.0-py3-none-any.whl (3.3MB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (1.16.4)\u001b[0m\n",
      "\u001b[31mCollecting PyWavelets>=0.4.0 (from scikit-image>=0.11.0->imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/cd/528dba0b474b08f6f9a3a5e1b4bb23d8e33ed5d9f0e321cc967c2607df05/PyWavelets-1.0.3-cp36-cp36m-manylinux1_x86_64.whl (4.4MB)\u001b[0m\n",
      "\u001b[31mCollecting networkx>=2.0 (from scikit-image>=0.11.0->imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/85/08/f20aef11d4c343b557e5de6b9548761811eb16e438cee3d32b1c66c8566b/networkx-2.3.zip (1.7MB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (2.8.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (1.1.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (0.10.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (2.4.0)\u001b[0m\n",
      "\u001b[31mCollecting decorator>=4.3.0 (from networkx>=2.0->scikit-image>=0.11.0->imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/5f/88/0075e461560a1e750a0dcbf77f1d9de775028c37a19a346a6c565a257399/decorator-4.4.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (41.0.1)\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: train, networkx\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-c8_micya/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "  Running setup.py bdist_wheel for networkx: started\u001b[0m\n",
      "\u001b[31m  Running setup.py bdist_wheel for networkx: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/de/63/64/3699be2a9d0ccdb37c7f16329acf3863fd76eda58c39c737af\u001b[0m\n",
      "\u001b[31mSuccessfully built train networkx\u001b[0m\n",
      "\u001b[31msagemaker-pytorch-container 1.2 has requirement Pillow==6.0.0, but you'll have pillow 5.4.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mInstalling collected packages: pillow, PyWavelets, imageio, decorator, networkx, scikit-image, Shapely, imgaug, train\n",
      "  Found existing installation: Pillow 6.0.0\n",
      "    Uninstalling Pillow-6.0.0:\u001b[0m\n",
      "\u001b[31m      Successfully uninstalled Pillow-6.0.0\u001b[0m\n",
      "\u001b[31mSuccessfully installed PyWavelets-1.0.3 Shapely-1.6.4.post2 decorator-4.4.0 imageio-2.5.0 imgaug-0.2.9 networkx-2.3 pillow-5.4.1 scikit-image-0.15.0 train-1.0.0\u001b[0m\n",
      "\u001b[31mYou are using pip version 18.1, however version 19.2.1 is available.\u001b[0m\n",
      "\u001b[31mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31m2019-08-06 06:19:56,903 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2019-08-06-06-15-30-723\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-central-1-505649883860/sagemaker-pytorch-2019-08-06-06-15-30-723/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[31mSM_HPS={\"epochs\":10}\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://sagemaker-eu-central-1-505649883860/sagemaker-pytorch-2019-08-06-06-15-30-723/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2019-08-06-06-15-30-723\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-central-1-505649883860/sagemaker-pytorch-2019-08-06-06-15-30-723/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--epochs\",\"10\"]\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[31mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m train --epochs 10\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mUsing device cuda.\u001b[0m\n",
      "\u001b[31mGet train data loader.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mEpoch: 1 #011Training Loss: 3.712942 #011Validation Loss: 2.561787\u001b[0m\n",
      "\u001b[31mEpoch: 2 #011Training Loss: 2.093467 #011Validation Loss: 1.663501\u001b[0m\n",
      "\u001b[31mEpoch: 3 #011Training Loss: 1.476688 #011Validation Loss: 1.265527\u001b[0m\n",
      "\u001b[31mEpoch: 4 #011Training Loss: 1.181037 #011Validation Loss: 1.050675\u001b[0m\n",
      "\u001b[31mEpoch: 5 #011Training Loss: 1.011723 #011Validation Loss: 0.915356\u001b[0m\n",
      "\u001b[31mEpoch: 6 #011Training Loss: 0.890234 #011Validation Loss: 0.823472\u001b[0m\n",
      "\u001b[31mEpoch: 7 #011Training Loss: 0.804099 #011Validation Loss: 0.756152\u001b[0m\n",
      "\u001b[31mEpoch: 8 #011Training Loss: 0.736964 #011Validation Loss: 0.703578\u001b[0m\n",
      "\u001b[31mEpoch: 9 #011Training Loss: 0.688688 #011Validation Loss: 0.662970\u001b[0m\n",
      "\u001b[31mEpoch: 10 #011Training Loss: 0.645880 #011Validation Loss: 0.631162\u001b[0m\n",
      "\u001b[31m2019-08-06 06:34:39,087 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2019-08-06 06:35:15 Uploading - Uploading generated training model\n",
      "2019-08-06 06:52:05 Completed - Training job completed\n",
      "Billable seconds: 2057\n",
      "CPU times: user 4.05 s, sys: 129 ms, total: 4.18 s\n",
      "Wall time: 37min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train your estimator on S3 training data\n",
    "estimator.fit({'train': train_location_orig_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-eu-central-1-505649883860/capstone-project-orig-data/sagemaker-pytorch-2019-08-06-06-15-30-723/output/model.tar.gz\n",
      "CPU times: user 13.6 ms, sys: 3.91 ms, total: 17.5 ms\n",
      "Wall time: 119 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# importing PyTorchModel\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "print(estimator.model_data)\n",
    "\n",
    "# Create a model from the trained estimator data\n",
    "# And point to the prediction script\n",
    "model = PyTorchModel(model_data=estimator.model_data,\n",
    "                     role = role,\n",
    "                     framework_version='1.1.0',\n",
    "                     entry_point='predict.py',\n",
    "                     source_dir=source_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.t2.large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogImages/valid\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'dogImages'\n",
    "print(os.path.join(data_dir, 'valid'))\n",
    "\n",
    "\n",
    "# we create some dictionaries\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'valid', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=5,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'valid', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 43, 110,  45,  38,  46])\n",
      "preds is [ 43 110  76  38  46]\n",
      "tensor([ 84,  13,   0, 111,  64])\n",
      "preds is [ 84  42   0 111  64]\n",
      "tensor([ 50,  30, 114,  40,  15])\n",
      "preds is [ 50  30 114  40  55]\n",
      "tensor([ 67, 103,  58, 130,  29])\n",
      "preds is [ 67 103  58  72  29]\n",
      "tensor([113,  95,  50,  59,  62])\n",
      "preds is [113  46  50  59  62]\n",
      "tensor([ 21,  80,  35, 126,   7])\n",
      "preds is [ 21  80  35 126   7]\n",
      "tensor([35, 51, 53, 38,  3])\n",
      "preds is [35 51 53 38  3]\n",
      "tensor([  1,  89, 116,  42, 124])\n",
      "preds is [  1 119 116 107 124]\n",
      "tensor([11, 12, 32, 11, 27])\n",
      "preds is [111  12  32  11 121]\n",
      "tensor([ 55, 122,  61,  41,  85])\n",
      "preds is [ 55 122  61  41  85]\n",
      "tensor([118,  81,  19,  91,  90])\n",
      "preds is [118  81  19  91  90]\n",
      "tensor([71, 85, 88, 55, 40])\n",
      "preds is [71 85 88 69 43]\n",
      "tensor([81, 12, 13, 53, 96])\n",
      "preds is [ 81 126  13  53 124]\n",
      "tensor([ 70,  92,  67, 117,  79])\n",
      "preds is [ 70 124  67 117  79]\n",
      "tensor([110,  52,  78, 116,   4])\n",
      "preds is [110  60  78 116   4]\n",
      "tensor([ 21, 123,  99,  63,  81])\n",
      "preds is [ 21 123  99  63  81]\n",
      "tensor([52, 74, 50, 94, 86])\n",
      "preds is [75 74 50 94 86]\n",
      "tensor([ 8, 10, 14, 17, 13])\n",
      "preds is [87 66 14 17 13]\n",
      "tensor([132, 124, 131,  47,  50])\n",
      "preds is [132 124 131  47  50]\n",
      "tensor([ 4, 46,  5, 25,  7])\n",
      "preds is [ 4 46  5 73  7]\n",
      "tensor([56, 18, 36, 13, 39])\n",
      "preds is [56 18 36 13 39]\n",
      "tensor([ 11,  43, 131,  58,  44])\n",
      "preds is [ 11  43 131  58  44]\n",
      "tensor([110,  78, 127, 102,   2])\n",
      "preds is [110 125 127 102   2]\n",
      "tensor([ 67,  30,  95, 125,  43])\n",
      "preds is [ 67  30  95 125  43]\n",
      "tensor([51, 19, 43,  4, 28])\n",
      "preds is [51 19 43  4 28]\n",
      "tensor([ 78, 126,  28,  85,  24])\n",
      "preds is [ 94 132  28  85  24]\n",
      "tensor([ 32,  45,  57,  75, 114])\n",
      "preds is [ 73  45  57  75 114]\n",
      "tensor([15, 42, 63, 70, 92])\n",
      "preds is [15 42 76 70 73]\n",
      "tensor([123,  14,  28,  68,   0])\n",
      "preds is [123  14  28  68  98]\n",
      "tensor([ 76,  17, 106,  56,  36])\n",
      "preds is [ 76  17 106  56  36]\n",
      "tensor([ 41,  66, 109,  93,  26])\n",
      "preds is [ 41  66 109  93  26]\n",
      "tensor([ 31, 132, 108,  31, 103])\n",
      "preds is [ 31 132 108  31 103]\n",
      "tensor([ 30,  30, 120,  70,  38])\n",
      "preds is [ 30  30 120  70  38]\n",
      "tensor([ 47,   2, 116,  60, 125])\n",
      "preds is [ 47   2 116  60 125]\n",
      "tensor([85, 28, 81, 54, 87])\n",
      "preds is [85 28 99 54 87]\n",
      "tensor([  6,  61, 112,   3,  46])\n",
      "preds is [  6  61 112  66  46]\n",
      "tensor([ 87,  86,  25, 102,  17])\n",
      "preds is [ 87  86  25 102  17]\n",
      "tensor([36, 36, 14, 15, 93])\n",
      "preds is [36 36 14 15 93]\n",
      "tensor([ 59,  98, 127,  17,   9])\n",
      "preds is [ 59  98 127  17   9]\n",
      "tensor([19, 46, 94, 53, 39])\n",
      "preds is [19 46 78 53 39]\n",
      "tensor([14, 99, 56, 85, 60])\n",
      "preds is [14 99 56 85 65]\n",
      "tensor([128,  33,  67,   7,  70])\n",
      "preds is [128  33  67   7  70]\n",
      "tensor([ 88,  82, 118, 132,  11])\n",
      "preds is [ 88  82 118 126  11]\n",
      "tensor([  0,   6, 132,  29, 102])\n",
      "preds is [  0   6 132  29 102]\n",
      "tensor([ 26, 106, 105,   4, 128])\n",
      "preds is [ 26 106 105   4  50]\n",
      "tensor([ 11, 126, 100, 111,  80])\n",
      "preds is [ 11 126 100 111  69]\n",
      "tensor([ 47,  69, 102,  55,   3])\n",
      "preds is [47 69 40 60  3]\n",
      "tensor([ 43, 112, 123, 108,  60])\n",
      "preds is [ 40 112 123 108  60]\n",
      "tensor([68, 40, 65, 82, 74])\n",
      "preds is [ 68  40  34  82 118]\n",
      "tensor([ 31,  70,  59,  29, 129])\n",
      "preds is [ 31 108  59  29 129]\n",
      "tensor([99, 53, 29, 76, 50])\n",
      "preds is [103  53  29  76  50]\n",
      "tensor([34, 15, 20, 32, 84])\n",
      "preds is [ 34  15  20  32 129]\n",
      "tensor([ 91,  46,  86, 116,   3])\n",
      "preds is [ 91  46  86 116  80]\n",
      "tensor([23, 41, 83, 37, 34])\n",
      "preds is [ 23 110   3  37  34]\n",
      "tensor([ 81, 129,  73,  98,   3])\n",
      "preds is [99 84 73 98  4]\n",
      "tensor([ 18,  34, 113,  75,  36])\n",
      "preds is [ 18  34 113  75  36]\n",
      "tensor([ 34,  26,  68, 123,  37])\n",
      "preds is [ 67  26  68 123 132]\n",
      "tensor([  5,  34, 131,  83,   8])\n",
      "preds is [  5  65 131 117  87]\n",
      "tensor([ 75,  93, 115,  73,  23])\n",
      "preds is [ 75  93 115  25  23]\n",
      "tensor([115,  53, 119,  94, 105])\n",
      "preds is [127  53 119  94 105]\n",
      "tensor([  4, 107, 126,  10, 120])\n",
      "preds is [  4 109 126  42 120]\n",
      "tensor([31, 45, 59, 22, 89])\n",
      "preds is [31 76 59 22 89]\n",
      "tensor([32, 93, 28, 60, 69])\n",
      "preds is [ 32  93  28  62 101]\n",
      "tensor([114, 130,  14,  70, 114])\n",
      "preds is [114 130  14  70 114]\n",
      "tensor([20, 14, 44, 66, 33])\n",
      "preds is [ 20  14 117  66  33]\n",
      "tensor([60, 31, 46, 13, 81])\n",
      "preds is [60 31 46 13 99]\n",
      "tensor([49, 59, 49,  4, 29])\n",
      "preds is [49 59 49  4 29]\n",
      "tensor([56, 90, 40, 35, 71])\n",
      "preds is [56 90 40 35 71]\n",
      "tensor([104,  51,  92, 103,  45])\n",
      "preds is [104  51  25 103  45]\n",
      "tensor([ 56,  29, 121,  69, 105])\n",
      "preds is [ 56  29  71 101 105]\n",
      "tensor([117, 111, 119,  68,  62])\n",
      "preds is [117 111 119  68  62]\n",
      "tensor([89, 83, 49, 70, 15])\n",
      "preds is [ 89 117  59  70  15]\n",
      "tensor([112,  78,  10,  22,  31])\n",
      "preds is [112  94  10  22  31]\n",
      "tensor([ 80,   0,  54, 115, 110])\n",
      "preds is [ 80   0  87 115 110]\n",
      "tensor([25, 98, 45, 74,  5])\n",
      "preds is [ 25  81  45  88 122]\n",
      "tensor([ 20, 117,  49,  61, 105])\n",
      "preds is [ 20 117  49  61 105]\n",
      "tensor([54, 39, 97, 48, 65])\n",
      "preds is [54 39 97 48 65]\n",
      "tensor([38, 19, 79,  3,  5])\n",
      "preds is [38 19 79  3  5]\n",
      "tensor([ 62,   2, 113,  90,  19])\n",
      "preds is [ 62   2 113  90  19]\n",
      "tensor([119,  81,  88,   7,  85])\n",
      "preds is [119  81  88   7  85]\n",
      "tensor([13, 72, 54, 39, 48])\n",
      "preds is [ 13  62  54  39 123]\n",
      "tensor([ 68, 116,  89,  66,   1])\n",
      "preds is [ 68 116  89  66 116]\n",
      "tensor([ 87,  60, 102,  35,   3])\n",
      "preds is [123  76  43  35   3]\n",
      "tensor([61, 45, 28, 19, 16])\n",
      "preds is [61 45 28 19 16]\n",
      "tensor([109,  90,  35, 106,  77])\n",
      "preds is [117  90  35 106  77]\n",
      "tensor([87, 55, 47, 91, 21])\n",
      "preds is [87 55 47 91 21]\n",
      "tensor([35, 57, 82, 76,  6])\n",
      "preds is [35 57 82 76  6]\n",
      "tensor([ 16,  68,  38,   8, 101])\n",
      "preds is [ 16  68  38  87 101]\n",
      "tensor([ 47,  21,  20,  38, 114])\n",
      "preds is [122  21  20  38 114]\n",
      "tensor([ 14,   0, 106,  38,  55])\n",
      "preds is [ 14   0 106  38 113]\n",
      "tensor([108, 100,  62,  74,  86])\n",
      "preds is [108 100  62  74  86]\n",
      "tensor([ 82, 117,  18,   1,  41])\n",
      "preds is [ 82 117  18   1  41]\n",
      "tensor([72, 33, 82,  4, 29])\n",
      "preds is [36 33 82  4 29]\n",
      "tensor([ 44,  23, 124,  13,  64])\n",
      "preds is [117  23 124  13  64]\n",
      "tensor([ 37,   6,  86,  38, 112])\n",
      "preds is [ 37   6  86  38 112]\n",
      "tensor([ 57, 108,  20,  62,  73])\n",
      "preds is [ 57 108  20  62  73]\n",
      "tensor([76, 44, 30, 74, 73])\n",
      "preds is [ 76  44  30 113  73]\n",
      "tensor([ 96, 113,  13, 105,  53])\n",
      "preds is [  2 113  13 105  53]\n",
      "tensor([78, 57, 83,  0, 77])\n",
      "preds is [ 78  57  83   0 120]\n",
      "tensor([ 66,  72,  65,  22, 128])\n",
      "preds is [ 66 104  65  22 128]\n",
      "tensor([ 72, 119, 118,  94,  11])\n",
      "preds is [130 119 118  94  11]\n",
      "tensor([ 79,   5, 107,  94,  69])\n",
      "preds is [ 79   5 107  78  69]\n",
      "tensor([14,  1, 21,  5, 43])\n",
      "preds is [14  1 21  5 43]\n",
      "tensor([121,  97,  44,  24, 127])\n",
      "preds is [121  97  44  24 127]\n",
      "tensor([ 43,  49,  27, 102,  79])\n",
      "preds is [43 49 27 39 79]\n",
      "tensor([22, 90, 54, 33, 17])\n",
      "preds is [22 90 54 33 17]\n",
      "tensor([26, 54, 59, 40, 12])\n",
      "preds is [26 54 59 40 12]\n",
      "tensor([96, 55, 95, 75, 16])\n",
      "preds is [96 55 95 75 16]\n",
      "tensor([ 78,  64, 130,  51,   1])\n",
      "preds is [ 78  79 130  51   1]\n",
      "tensor([ 40, 129,   7,   1,  24])\n",
      "preds is [ 40 129   7   1  24]\n",
      "tensor([ 10,  22, 127,  11, 103])\n",
      "preds is [ 10  22 127  11 103]\n",
      "tensor([45, 64, 31, 89, 55])\n",
      "preds is [ 45  64  31  89 103]\n",
      "tensor([123, 121, 104,  20,  39])\n",
      "preds is [123  71 104  20  39]\n",
      "tensor([97, 88, 67, 75, 30])\n",
      "preds is [97 88 67 75 30]\n",
      "tensor([17, 28, 69, 40,  0])\n",
      "preds is [17 28 69 33  0]\n",
      "tensor([  6,  18,  71,  11, 100])\n",
      "preds is [  6  18 121  11 100]\n",
      "tensor([ 13, 122,  10,  37,  47])\n",
      "preds is [ 13 122  10  37 114]\n",
      "tensor([  7,  61,  10,   0, 103])\n",
      "preds is [  7  61  10   0 103]\n",
      "tensor([ 57, 121,  48,  35,  22])\n",
      "preds is [ 57 121  48  35  22]\n",
      "tensor([58,  1, 12, 67, 41])\n",
      "preds is [ 58  61 111 105  41]\n",
      "tensor([62,  8,  2, 22, 47])\n",
      "preds is [67  8  2 22 47]\n",
      "tensor([ 43,  63, 107,  96,  75])\n",
      "preds is [  7  63  42 124  75]\n",
      "tensor([84, 61, 78, 15, 86])\n",
      "preds is [84 61 78 15 86]\n",
      "tensor([ 18,   1, 128,  71, 120])\n",
      "preds is [ 18   1  75  71 120]\n",
      "tensor([100,  42,   9,  80,  51])\n",
      "preds is [100  42   9  80 129]\n",
      "tensor([28,  2, 34, 51, 16])\n",
      "preds is [28  2 34 51 16]\n",
      "tensor([124,  59, 100,  68,   2])\n",
      "preds is [124  59 100  68   2]\n",
      "tensor([23, 40, 69, 81, 42])\n",
      "preds is [ 23  40 101 124  66]\n",
      "tensor([ 94, 114, 106,  26,  28])\n",
      "preds is [ 94 114 106  26  28]\n",
      "tensor([41, 91, 73, 46, 55])\n",
      "preds is [41 91 92 46 69]\n",
      "tensor([ 67, 109,  10,  52,  33])\n",
      "preds is [ 67 117  10  63  33]\n",
      "tensor([112,   3,  63, 119,  99])\n",
      "preds is [112   3  45 119  99]\n",
      "tensor([ 60, 118,   4, 111,  89])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds is [ 60 118   4 111  89]\n",
      "tensor([ 95, 108,  39,  12,  26])\n",
      "preds is [ 95 108  39  12  26]\n",
      "tensor([117,  41,  88,  72, 122])\n",
      "preds is [117  41  16 130 122]\n",
      "tensor([ 27,   9, 117, 104,  76])\n",
      "preds is [ 27   9 117 104  76]\n",
      "tensor([ 23,  71, 101,  59,   9])\n",
      "preds is [ 23  71 101  59   9]\n",
      "tensor([86,  4, 16, 77, 27])\n",
      "preds is [86  4 16 80 27]\n",
      "tensor([90, 95, 83, 65, 49])\n",
      "preds is [90 95 83 65 59]\n",
      "tensor([89,  6, 90, 97, 79])\n",
      "preds is [ 89   6  90  97 121]\n",
      "tensor([ 23,  44,  63,  45, 129])\n",
      "preds is [ 23  44  45  45 129]\n",
      "tensor([ 21, 122, 128,  60,  88])\n",
      "preds is [ 21 122 128  62  88]\n",
      "tensor([106,  15, 125,  45,  56])\n",
      "preds is [106  15 125  45  56]\n",
      "tensor([31,  6, 17, 96, 85])\n",
      "preds is [31  6 17  2 85]\n",
      "tensor([109, 129,  80,  33,  88])\n",
      "preds is [127 129  89  33  88]\n",
      "tensor([ 48,  48,  91, 101,  24])\n",
      "preds is [ 48  48  91 101  24]\n",
      "tensor([25, 83, 58, 35, 52])\n",
      "preds is [25 83 69 35 52]\n",
      "tensor([111, 102,  56,   7,  97])\n",
      "preds is [111 102  56   7  97]\n",
      "tensor([50, 62, 23, 42, 14])\n",
      "preds is [50 62 23 42 14]\n",
      "tensor([ 37,  16,  89,  36, 104])\n",
      "preds is [ 37  16  89  36 104]\n",
      "tensor([ 15, 115,  58,  48, 122])\n",
      "preds is [ 15 115  58  48 114]\n",
      "tensor([92, 52, 57, 56, 67])\n",
      "preds is [92 52 57 56 67]\n",
      "tensor([ 7, 18, 50, 30, 16])\n",
      "preds is [ 7 18 50 30 16]\n",
      "tensor([116, 114,  44,  19,  57])\n",
      "preds is [116 114  44  19  57]\n",
      "tensor([50, 64, 41, 54, 98])\n",
      "preds is [105  64  41  54  98]\n",
      "tensor([ 37, 114,  75,  10,  77])\n",
      "preds is [ 37 114  75  10  77]\n",
      "tensor([123,  25, 111,  23, 105])\n",
      "preds is [123  25 111  23 105]\n",
      "tensor([20, 33, 82, 56, 53])\n",
      "preds is [124  33  82  56  53]\n",
      "tensor([26, 52, 26, 87, 28])\n",
      "preds is [26 62 26 87 28]\n",
      "tensor([55, 58, 11,  5, 86])\n",
      "preds is [55 69 36  5 86]\n",
      "tensor([111, 100,  77,  33, 110])\n",
      "preds is [111 100  31  33 110]\n",
      "tensor([75,  5, 98, 71, 20])\n",
      "preds is [ 75   5  98 121  20]\n",
      "tensor([19, 39,  9, 14, 96])\n",
      "preds is [19 39  9 14 96]\n",
      "tensor([80,  9, 87, 32, 78])\n",
      "preds is [80 94 87 32 94]\n",
      "tensor([  4,  93, 128,  80,  12])\n",
      "preds is [  4  93 128  80 110]\n",
      "tensor([70, 38, 84, 37, 16])\n",
      "preds is [ 70  38 129  37  16]\n",
      "tensor([ 40, 126, 117,  10,  42])\n",
      "preds is [ 40 126 117  42  42]\n",
      "tensor([22])\n",
      "preds is 22\n",
      "Acc: 83.61%\n",
      "tensor(0.8361, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "testacc=test_acc(iter(dataloaders['test']), predictor)\n",
    "print(testacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_pytorch_style_transfer\n",
      "s3://sagemaker-eu-central-1-505649883860/capstone-project-orig-data/\n"
     ]
    }
   ],
   "source": [
    "print(source_dir)\n",
    "print(train_location_orig_data)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
