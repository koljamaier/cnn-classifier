{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define imports\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "#import PIL\n",
    "import os, random\n",
    "\n",
    "from glob import glob\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from IPython.display import display, Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "\n",
    "\n",
    "import copy\n",
    "#import cv2                \n",
    "\n",
    "from io import open\n",
    "import json\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, os.path, random\n",
    "from PIL import Image\n",
    "import requests\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# my imports\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join, abspath\n",
    "from style_transfer.stylize import transfer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All images are resized to 224x224 and normalized\n",
    "# Only training images receive further augmentation\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogImages/valid\n",
      "{'train': 59573, 'valid': 835, 'test': 836}\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'dogImages_style_transfer'\n",
    "print(os.path.join(data_dir, 'valid'))\n",
    "\n",
    "\n",
    "# we create some dictionaries\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'valid', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=5,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'valid', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid', 'test']}\n",
    "print(dataset_sizes)\n",
    "class_names = image_datasets['train'].classes\n",
    "n_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create an S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# this is the S3 data_dir name\n",
    "data_dir = 'dogImages'\n",
    "train_dir = 'train'\n",
    "\n",
    "# set prefix, a descriptive name for a directory  \n",
    "prefix = 'capstone-project'\n",
    "\n",
    "# upload data for the first time; otherwise use the second expression (because the S3 upload takes some time)\n",
    "#train_location = sagemaker_session.upload_data(os.path.join(data_dir), key_prefix=prefix)\n",
    "train_location = 's3://{}/{}/'.format(bucket, prefix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your import and estimator code, here\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix)\n",
    "\n",
    "# note: this PyTorch estimator is specified with code that includes\n",
    "# the preprocessing with the imgaug library and is trained on the style\n",
    "# transferred images\n",
    "source_dir = 'source_pytorch'\n",
    "\n",
    "# instantiate a pytorch estimator\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                    source_dir=source_dir,\n",
    "                    role=role,\n",
    "                    framework_version='1.1.0',\n",
    "                    train_instance_count=1,\n",
    "                    #train_instance_type='ml.c4.xlarge',\n",
    "                    train_instance_type='ml.p2.xlarge',\n",
    "                    output_path=output_path,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    hyperparameters={\n",
    "                        'epochs': 10\n",
    "                    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-04 19:50:35 Starting - Starting the training job...\n",
      "2019-08-04 19:50:39 Starting - Launching requested ML instances......\n",
      "2019-08-04 19:51:41 Starting - Preparing the instances for training......\n",
      "2019-08-04 19:52:57 Downloading - Downloading input data..........................................\n",
      "2019-08-04 19:59:58 Training - Training image download completed. Training in progress.\n",
      "\u001b[31mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[31mbash: no job control in this shell\u001b[0m\n",
      "\u001b[31m2019-08-04 20:00:00,071 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[31m2019-08-04 20:00:00,096 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[31m2019-08-04 20:00:03,119 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[31m2019-08-04 20:00:03,431 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2019-08-04 20:00:03,432 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2019-08-04 20:00:03,432 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2019-08-04 20:00:03,432 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mCollecting pillow==5.4.1 (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\u001b[0m\n",
      "\u001b[31mCollecting imgaug==0.2.9 (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/17/a9/36de8c0e1ffb2d86f871cac60e5caa910cbbdb5f4741df5ef856c47f4445/imgaug-0.2.9-py2.py3-none-any.whl (753kB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (1.16.4)\u001b[0m\n",
      "\u001b[31mCollecting Shapely (from imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/38/b6/b53f19062afd49bb5abd049aeed36f13bf8d57ef8f3fa07a5203531a0252/Shapely-1.6.4.post2-cp36-cp36m-manylinux1_x86_64.whl (1.5MB)\u001b[0m\n",
      "\u001b[31mCollecting imageio (from imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/af/0a/943c965d372dae0b1f1482677d29030ab834351a61a9a632fd62f27f1523/imageio-2.5.0-py3-none-any.whl (3.3MB)\u001b[0m\n",
      "\u001b[31mCollecting scikit-image>=0.11.0 (from imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/ab/674e168bf7d0bc597218b3bec858d02c23fbac9ec1fec9cad878c6cee95f/scikit_image-0.15.0-cp36-cp36m-manylinux1_x86_64.whl (26.3MB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (1.12.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (1.3.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (4.0.1.24)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (3.1.0)\u001b[0m\n",
      "\u001b[31mCollecting PyWavelets>=0.4.0 (from scikit-image>=0.11.0->imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/cd/528dba0b474b08f6f9a3a5e1b4bb23d8e33ed5d9f0e321cc967c2607df05/PyWavelets-1.0.3-cp36-cp36m-manylinux1_x86_64.whl (4.4MB)\u001b[0m\n",
      "\u001b[31mCollecting networkx>=2.0 (from scikit-image>=0.11.0->imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/85/08/f20aef11d4c343b557e5de6b9548761811eb16e438cee3d32b1c66c8566b/networkx-2.3.zip (1.7MB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (0.10.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (2.4.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (2.8.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (1.1.0)\u001b[0m\n",
      "\u001b[31mCollecting decorator>=4.3.0 (from networkx>=2.0->scikit-image>=0.11.0->imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/5f/88/0075e461560a1e750a0dcbf77f1d9de775028c37a19a346a6c565a257399/decorator-4.4.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (41.0.1)\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: train, networkx\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-o6hnkunz/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "  Running setup.py bdist_wheel for networkx: started\u001b[0m\n",
      "\u001b[31m  Running setup.py bdist_wheel for networkx: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/de/63/64/3699be2a9d0ccdb37c7f16329acf3863fd76eda58c39c737af\u001b[0m\n",
      "\u001b[31mSuccessfully built train networkx\u001b[0m\n",
      "\u001b[31msagemaker-pytorch-container 1.2 has requirement Pillow==6.0.0, but you'll have pillow 5.4.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mInstalling collected packages: pillow, Shapely, imageio, PyWavelets, decorator, networkx, scikit-image, imgaug, train\n",
      "  Found existing installation: Pillow 6.0.0\n",
      "    Uninstalling Pillow-6.0.0:\n",
      "      Successfully uninstalled Pillow-6.0.0\u001b[0m\n",
      "\u001b[31mSuccessfully installed PyWavelets-1.0.3 Shapely-1.6.4.post2 decorator-4.4.0 imageio-2.5.0 imgaug-0.2.9 networkx-2.3 pillow-5.4.1 scikit-image-0.15.0 train-1.0.0\u001b[0m\n",
      "\u001b[31mYou are using pip version 18.1, however version 19.2.1 is available.\u001b[0m\n",
      "\u001b[31mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31m2019-08-04 20:00:12,244 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2019-08-04-19-50-35-540\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-central-1-505649883860/sagemaker-pytorch-2019-08-04-19-50-35-540/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[31mSM_HPS={\"epochs\":10}\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://sagemaker-eu-central-1-505649883860/sagemaker-pytorch-2019-08-04-19-50-35-540/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2019-08-04-19-50-35-540\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-central-1-505649883860/sagemaker-pytorch-2019-08-04-19-50-35-540/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--epochs\",\"10\"]\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[31mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m train --epochs 10\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mUsing device cuda.\u001b[0m\n",
      "\u001b[31mGet train data loader.\u001b[0m\n",
      "\u001b[31mEpoch: 1 #011Training Loss: 26.674755 #011Validation Loss: 7.162729\u001b[0m\n",
      "\u001b[31mEpoch: 2 #011Training Loss: 34.419785 #011Validation Loss: 7.321543\u001b[0m\n",
      "\u001b[31mEpoch: 3 #011Training Loss: 37.806259 #011Validation Loss: 8.022751\u001b[0m\n",
      "\u001b[31mEpoch: 4 #011Training Loss: 39.815794 #011Validation Loss: 7.985204\u001b[0m\n",
      "\u001b[31mEpoch: 5 #011Training Loss: 41.511583 #011Validation Loss: 9.034338\u001b[0m\n",
      "\u001b[31mEpoch: 6 #011Training Loss: 42.272636 #011Validation Loss: 9.284262\u001b[0m\n",
      "\u001b[31mEpoch: 7 #011Training Loss: 43.557440 #011Validation Loss: 9.195464\u001b[0m\n",
      "\u001b[31mEpoch: 8 #011Training Loss: 43.956678 #011Validation Loss: 9.054931\u001b[0m\n",
      "\u001b[31mEpoch: 9 #011Training Loss: 44.419265 #011Validation Loss: 8.957233\u001b[0m\n",
      "\u001b[31mEpoch: 10 #011Training Loss: 45.134310 #011Validation Loss: 8.717339\u001b[0m\n",
      "\u001b[31m2019-08-05 00:59:00,875 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2019-08-05 00:59:05 Uploading - Uploading generated training model\n",
      "2019-08-05 01:00:26 Completed - Training job completed\n",
      "Billable seconds: 18450\n",
      "CPU times: user 34.1 s, sys: 1.46 s, total: 35.5 s\n",
      "Wall time: 5h 10min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train your estimator on S3 training data\n",
    "estimator.fit({'train': train_location})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# importing PyTorchModel\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "print(estimator.model_data)\n",
    "\n",
    "# Create a model from the trained estimator data\n",
    "# And point to the prediction script\n",
    "model = PyTorchModel(model_data=estimator.model_data,\n",
    "                     role = role,\n",
    "                     framework_version='1.1.0',\n",
    "                     entry_point='predict.py',\n",
    "                     source_dir=source_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "# ATTENTION: Please use the ml.t2.large instance here. Otherwise the deployment will fail because of resource constraints\n",
    "# predictor = model.deploy(initial_instance_count=1, instance_type='ml.t2.medium')\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.t2.large')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 41,  55, 103,  96, 111])\n",
      "preds is [  0  55 103   2 111]\n",
      "tensor([115,  56,  99, 124, 129])\n",
      "preds is [115  56  81 124 129]\n",
      "tensor([ 30,  48, 109,  82, 106])\n",
      "preds is [ 30  48  47  82 106]\n",
      "tensor([ 94,  70,  48, 103,  73])\n",
      "preds is [ 94  70  48 103  32]\n",
      "tensor([ 68, 100, 104,  81,  24])\n",
      "preds is [ 68 100 104  81  24]\n",
      "tensor([ 28, 127, 107,  75,  31])\n",
      "preds is [ 28 127  10  75  31]\n",
      "tensor([ 39, 116,  46,  14, 123])\n",
      "preds is [ 39 116  46  14 123]\n",
      "tensor([78, 67, 19, 80, 86])\n",
      "preds is [94 67 19 89 86]\n",
      "tensor([ 9, 45, 35, 64, 79])\n",
      "preds is [ 7 76 35 64 64]\n",
      "tensor([ 28,   4,  25,  41, 113])\n",
      "preds is [ 28   4  25 110 113]\n",
      "tensor([ 98,  99, 103,  68,  69])\n",
      "preds is [ 98  81 103  68  69]\n",
      "tensor([120,  37,  57, 116,  20])\n",
      "preds is [120  37  57 116  20]\n",
      "tensor([90, 41, 73, 28, 18])\n",
      "preds is [90 41 73 28 18]\n",
      "tensor([ 83,  60,  81, 118,  10])\n",
      "preds is [114  60  81 113  10]\n",
      "tensor([100,  40,  15, 109,  35])\n",
      "preds is [100  40  15 109  35]\n",
      "tensor([126,  59,  12,  63,  94])\n",
      "preds is [132  59  12  63  94]\n",
      "tensor([43, 11,  5, 20, 33])\n",
      "preds is [40 11  5 20 33]\n",
      "tensor([71, 80, 49, 70, 68])\n",
      "preds is [121  80  49 108  68]\n",
      "tensor([ 26,  15,  68, 111, 121])\n",
      "preds is [ 26  15  68  36 121]\n",
      "tensor([ 11, 118,   1,  34, 103])\n",
      "preds is [ 11 118  61  34 103]\n",
      "tensor([118, 115,  88,  65,  29])\n",
      "preds is [ 81 115  88  65  29]\n",
      "tensor([132,  97,  75,  48,  45])\n",
      "preds is [132  97  75 123  45]\n",
      "tensor([ 85,  85,  42, 117,  40])\n",
      "preds is [ 85  85  38 117  40]\n",
      "tensor([ 65,  60,  87,  69, 129])\n",
      "preds is [ 65  60  87 101 129]\n",
      "tensor([ 2, 19, 38, 76,  4])\n",
      "preds is [ 2 19 38 76  4]\n",
      "tensor([ 31,  91, 117,  50,  71])\n",
      "preds is [ 31  91 117 105  46]\n",
      "tensor([130,  19, 116,  21,  44])\n",
      "preds is [ 86  19 116  21  44]\n",
      "tensor([ 35,  95,  70, 119,  30])\n",
      "preds is [ 35  39  70 119  30]\n",
      "tensor([100,  43,  67,  22,  64])\n",
      "preds is [100   7  67  22  79]\n",
      "tensor([  6,  56,  10,  52, 114])\n",
      "preds is [  6  56  10  52 114]\n",
      "tensor([112,  25,  72,  37,  21])\n",
      "preds is [112  25  61  37  21]\n",
      "tensor([66, 47, 58, 74, 62])\n",
      "preds is [ 66  47  58 100  62]\n",
      "tensor([ 37,  98,  85,  67, 115])\n",
      "preds is [ 37  98  85  67 115]\n",
      "tensor([86, 91, 16, 16, 90])\n",
      "preds is [86 91 16 16 90]\n",
      "tensor([14, 14, 72, 61, 66])\n",
      "preds is [14 14 72 76 66]\n",
      "tensor([ 6, 50, 68, 85, 46])\n",
      "preds is [ 6 50 68 85 46]\n",
      "tensor([26, 13,  4, 71, 39])\n",
      "preds is [26 13  4 71 39]\n",
      "tensor([ 62,  58,  70,   7, 108])\n",
      "preds is [62 69 70  7 66]\n",
      "tensor([ 23,   0, 102,  18,  17])\n",
      "preds is [ 23   0 102  18  17]\n",
      "tensor([33, 14, 42, 43, 53])\n",
      "preds is [33 14 66 43 53]\n",
      "tensor([113, 121, 108,  86,  71])\n",
      "preds is [113  71  19  86  71]\n",
      "tensor([82,  0, 14, 82, 15])\n",
      "preds is [82 81 14 82 55]\n",
      "tensor([ 13,  35, 104,  49,   3])\n",
      "preds is [ 13  35 104  59   3]\n",
      "tensor([12, 99, 50, 53, 58])\n",
      "preds is [110  81  50  53  58]\n",
      "tensor([ 90,  92,  57, 117,  26])\n",
      "preds is [ 90  25 100 117  26]\n",
      "tensor([78, 65, 22, 10, 96])\n",
      "preds is [78 65 22 10  0]\n",
      "tensor([30, 59, 52, 81, 89])\n",
      "preds is [53 59 52 81 89]\n",
      "tensor([ 50,  49,  43, 122,  14])\n",
      "preds is [ 50  46  43 122  14]\n",
      "tensor([  2, 121,  83, 130,  40])\n",
      "preds is [  2 121   3  86  40]\n",
      "tensor([44, 88, 45, 35, 47])\n",
      "preds is [ 44  88  45  35 122]\n",
      "tensor([44, 64, 26, 94, 69])\n",
      "preds is [117  79  26  94  58]\n",
      "tensor([81, 23,  1,  9, 57])\n",
      "preds is [81 23  1 94 57]\n",
      "tensor([ 46,  86,  60,  44, 126])\n",
      "preds is [ 46  86  62  44 132]\n",
      "tensor([ 18, 124,   2, 106,  31])\n",
      "preds is [ 18 124   2 106  31]\n",
      "tensor([20, 22, 84, 74, 16])\n",
      "preds is [ 20  22  84 113  16]\n",
      "tensor([ 39,  25,  80,  11, 111])\n",
      "preds is [ 39  25  80  11 111]\n",
      "tensor([ 40,  74, 113,   8,  87])\n",
      "preds is [33 74 35 34 34]\n",
      "tensor([35, 62, 45, 38, 58])\n",
      "preds is [35 85 45 38 17]\n",
      "tensor([102,  35,  66, 129,  96])\n",
      "preds is [102  35  66 129  96]\n",
      "tensor([ 13,  30,  72, 100,  87])\n",
      "preds is [127  30 113 100  87]\n",
      "tensor([118,  97,  11,  28,  56])\n",
      "preds is [81 97 11 28 56]\n",
      "tensor([ 76, 116,  34,  33, 102])\n",
      "preds is [ 76 116  67  33 102]\n",
      "tensor([ 21,  28,  23, 103,  25])\n",
      "preds is [ 70  28  23 103  25]\n",
      "tensor([54, 70, 67,  0, 22])\n",
      "preds is [54 21 67  0 22]\n",
      "tensor([  9,  54,  95, 129,  12])\n",
      "preds is [  9  54  95 129  12]\n",
      "tensor([84, 87, 29, 47, 71])\n",
      "preds is [45 87 29 47 71]\n",
      "tensor([ 75,   7, 110,   7,  53])\n",
      "preds is [ 75   7 110   7  53]\n",
      "tensor([ 20,  83, 126,  23,   3])\n",
      "preds is [ 20  44 132  23   3]\n",
      "tensor([  2, 119, 116,  60,  19])\n",
      "preds is [  2 119 116  60  70]\n",
      "tensor([15, 45, 67, 79,  4])\n",
      "preds is [15 45 67 79  4]\n",
      "tensor([ 96,  20, 122, 112,  68])\n",
      "preds is [  2  20 122 112  68]\n",
      "tensor([ 62,   7, 114,   4,  67])\n",
      "preds is [ 62   7 114   4  67]\n",
      "tensor([123,  60,  74,  52,  44])\n",
      "preds is [ 52  76  57  62 109]\n",
      "tensor([10, 10, 73, 93, 65])\n",
      "preds is [10 10 73 93 65]\n",
      "tensor([  7,  32,  51, 120,  22])\n",
      "preds is [  7  32  36 120  22]\n",
      "tensor([ 49,  94, 110, 105,  45])\n",
      "preds is [ 49  94 110 105  45]\n",
      "tensor([ 89,  75,  92,  50, 117])\n",
      "preds is [ 89  75  92  50 109]\n",
      "tensor([18, 82, 54, 33, 84])\n",
      "preds is [18 82 67 33 62]\n",
      "tensor([ 55,  81,  38,  78, 108])\n",
      "preds is [ 55  81  38  94 108]\n",
      "tensor([ 6, 77, 63, 40,  5])\n",
      "preds is [ 6 77 63 40  5]\n",
      "tensor([132,  53, 119, 102,  26])\n",
      "preds is [132  53 119 102  26]\n",
      "tensor([114,  98,  14,  41, 128])\n",
      "preds is [114  81  14  41  97]\n",
      "tensor([16, 33, 55, 86, 27])\n",
      "preds is [16 33 55 86 27]\n",
      "tensor([ 93,  80,  90,  11, 131])\n",
      "preds is [ 93  80  90  28 131]\n",
      "tensor([ 57, 132,  37, 128,  32])\n",
      "preds is [ 57 132  37 128  32]\n",
      "tensor([101,   7, 114,  27,  55])\n",
      "preds is [101   7 114  27  55]\n",
      "tensor([  0, 112,  10,  44,  94])\n",
      "preds is [  0 112  10  44  94]\n",
      "tensor([ 42,  50, 111,  46, 104])\n",
      "preds is [ 42  50 111  46 104]\n",
      "tensor([ 75, 101,  30,  56,  12])\n",
      "preds is [ 75 101  30  56 126]\n",
      "tensor([ 97,   9, 106,  32,  80])\n",
      "preds is [ 97   9 106  32  80]\n",
      "tensor([ 89,  29, 108,  74,  54])\n",
      "preds is [ 89  29 108  74 123]\n",
      "tensor([113,  42, 114,  77,  56])\n",
      "preds is [113  75 114   7  56]\n",
      "tensor([ 70, 105,  59,  89,   4])\n",
      "preds is [ 70 105  59  89   4]\n",
      "tensor([75, 68, 51, 78, 79])\n",
      "preds is [75 68 51 94 79]\n",
      "tensor([127,  63,  56,   8,  33])\n",
      "preds is [127  63  56  34  33]\n",
      "tensor([108,  87,  58,  92,  83])\n",
      "preds is [108  87  17  73 117]\n",
      "tensor([96,  2, 76, 61, 11])\n",
      "preds is [96  2 76 61 11]\n",
      "tensor([ 23, 110,  38, 121, 124])\n",
      "preds is [ 23 110  38  71 124]\n",
      "tensor([47, 42, 14, 60, 41])\n",
      "preds is [47 42 14 62 41]\n",
      "tensor([ 13,  37,  64, 128,  40])\n",
      "preds is [ 13  37  64 128  40]\n",
      "tensor([ 52,  38, 102,   4, 105])\n",
      "preds is [ 52  38 102   4 105]\n",
      "tensor([ 38,  97,   0, 109,  56])\n",
      "preds is [ 38  97   0 109  56]\n",
      "tensor([43, 20, 45, 78, 60])\n",
      "preds is [ 40  20  45 125  60]\n",
      "tensor([ 76,  88,  35, 105,  12])\n",
      "preds is [ 76  88  35 105  12]\n",
      "tensor([ 20, 105,  89,  45,  36])\n",
      "preds is [ 20 105 119  45  36]\n",
      "tensor([ 15, 117,  22, 131,  27])\n",
      "preds is [ 15 117  22 131  27]\n",
      "tensor([ 0,  7, 83, 51, 18])\n",
      "preds is [ 0  7  5 51 18]\n",
      "tensor([ 95, 130,  28,  67, 126])\n",
      "preds is [ 95  72  28  67 132]\n",
      "tensor([ 29,  19,  92, 114, 125])\n",
      "preds is [ 29  19 124 114 125]\n",
      "tensor([ 12,  17,   1, 105,  48])\n",
      "preds is [ 12  17  35 105 114]\n",
      "tensor([55, 82, 29, 60, 14])\n",
      "preds is [55 82 29 34 14]\n",
      "tensor([ 89, 117,  34,  38,  40])\n",
      "preds is [ 89 117  34  38  40]\n",
      "tensor([ 27,  41, 110,  80,   4])\n",
      "preds is [ 61  41 110  58   4]\n",
      "tensor([ 93,  36, 111,  90,  23])\n",
      "preds is [ 93  36 111  90  23]\n",
      "tensor([61, 78, 34, 39, 57])\n",
      "preds is [61 78 65 39 57]\n",
      "tensor([66, 10,  0, 64, 98])\n",
      "preds is [66 10  0 64 98]\n",
      "tensor([28, 49, 14, 87, 51])\n",
      "preds is [28 49 14 87 36]\n",
      "tensor([ 46,  13, 123, 125, 123])\n",
      "preds is [ 46  13 123 125 123]\n",
      "tensor([ 40,  85, 107,  42,   3])\n",
      "preds is [ 40  85 107  42   3]\n",
      "tensor([ 48, 106,  71,  88,  23])\n",
      "preds is [ 48 106  71  88  23]\n",
      "tensor([  5,  28,  19,  83, 124])\n",
      "preds is [  5  28  19  53 124]\n",
      "tensor([ 17,  39, 114,  96,  59])\n",
      "preds is [ 17  39 114 124  59]\n",
      "tensor([ 32,  16,  22,  24, 128])\n",
      "preds is [32 16 22 24 97]\n",
      "tensor([102,  23,  55,  10,  61])\n",
      "preds is [102  23   2  10 129]\n",
      "tensor([56, 86, 67, 95, 76])\n",
      "preds is [56 86 67 95 34]\n",
      "tensor([ 91, 104,  54,  28,  61])\n",
      "preds is [ 91 104  54  28 129]\n",
      "tensor([13, 17, 41, 79, 91])\n",
      "preds is [13 58 41 79 91]\n",
      "tensor([15, 50, 20, 13, 43])\n",
      "preds is [15 50 20 13 43]\n",
      "tensor([107,   5,  31, 129, 100])\n",
      "preds is [109   5  31 129 100]\n",
      "tensor([ 39, 122,  88,  62,  79])\n",
      "preds is [ 39 122  88  62  79]\n",
      "tensor([ 48, 122,  21,  36,  47])\n",
      "preds is [48 90 21 36 47]\n",
      "tensor([ 19, 120,  94, 128,  75])\n",
      "preds is [ 19 127  94 128  75]\n",
      "tensor([85, 49, 99, 77, 29])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds is [85 49 81  9 29]\n",
      "tensor([78, 81, 18, 58, 86])\n",
      "preds is [94 81 18 58 86]\n",
      "tensor([  6,   1, 112,  73,  33])\n",
      "preds is [ 6  1 94 73 33]\n",
      "tensor([ 91,  28,  98, 111,  15])\n",
      "preds is [ 91  28 100  36  15]\n",
      "tensor([119,  84,   1,  17,  33])\n",
      "preds is [119  36  35  17  33]\n",
      "tensor([ 29,  46,  26, 131,  43])\n",
      "preds is [ 29  46  26 131   7]\n",
      "tensor([17, 54, 81, 62, 53])\n",
      "preds is [ 17  46 124  62  53]\n",
      "tensor([114,  21,  93,   9,  78])\n",
      "preds is [114  53  93   9  78]\n",
      "tensor([13, 36, 70, 59, 44])\n",
      "preds is [13 36 70 59 44]\n",
      "tensor([  1,  55, 132,  34,  63])\n",
      "preds is [  1  55 132  34  45]\n",
      "tensor([72, 53, 19, 77, 55])\n",
      "preds is [ 62  53   9  77 113]\n",
      "tensor([106,  89,  37,  72,  90])\n",
      "preds is [106  89 132 124  90]\n",
      "tensor([ 30,  52, 123,  16,   6])\n",
      "preds is [ 30  45 123  16  36]\n",
      "tensor([  1,   5, 127, 123, 111])\n",
      "preds is [116   5 127 123 111]\n",
      "tensor([117,  38, 116,  26,  31])\n",
      "preds is [117  38 116  26  31]\n",
      "tensor([41,  8, 11, 88, 37])\n",
      "preds is [41 34 11 16 37]\n",
      "tensor([31, 36,  6, 11, 57])\n",
      "preds is [31 36 15 11 57]\n",
      "tensor([ 24,   3,  61, 112,  47])\n",
      "preds is [ 24  66  61 112  47]\n",
      "tensor([ 63, 122,  59,   3,  95])\n",
      "preds is [ 63 122  59   3  46]\n",
      "tensor([  7,  13, 125,  85,   5])\n",
      "preds is [  7  13 125  85   5]\n",
      "tensor([ 86,  51,   3,  62, 115])\n",
      "preds is [ 86  51   4  62 115]\n",
      "tensor([52, 36,  8, 59, 11])\n",
      "preds is [63 36  8 59 11]\n",
      "tensor([119,  54, 102,   4,  16])\n",
      "preds is [119  54  40   4  35]\n",
      "tensor([ 22,  34,  59,  31, 127])\n",
      "preds is [ 22  34  59  31 127]\n",
      "tensor([ 75,  10, 110,  77,   3])\n",
      "preds is [ 75  66 110  77   7]\n",
      "tensor([46, 81, 53, 69, 69])\n",
      "preds is [ 46  81  53 101  69]\n",
      "tensor([31, 15,  2, 55, 97])\n",
      "preds is [31 15  2 55 97]\n",
      "tensor([45,  5, 40,  1,  9])\n",
      "preds is [ 76 122  40   1   9]\n",
      "tensor([70, 39, 25, 43, 50])\n",
      "preds is [70 39 25 43 50]\n",
      "tensor([47, 57, 82, 17, 80])\n",
      "preds is [114  57  82  17  89]\n",
      "tensor([ 16, 109,   6,  88, 128])\n",
      "preds is [ 16 109  15  88 128]\n",
      "tensor([  3,  26,   4, 101,  93])\n",
      "preds is [  3  26   4 101  93]\n",
      "tensor([ 51,  24,  56,   5, 100])\n",
      "preds is [ 51  55  56   5 100]\n",
      "tensor([106,  73,  30,  21, 126])\n",
      "preds is [106  73  30  20 132]\n",
      "tensor([32, 89, 69,  0, 38])\n",
      "preds is [73 89 58  0 38]\n",
      "tensor([90])\n",
      "preds is 90\n",
      "Acc: 79.90%\n",
      "tensor(0.7990, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "def test_acc(test_set, predictor):\n",
    "    ''' \n",
    "    This method calculates our accuracy metric. For this, it will send \n",
    "    batches of data to the endpoint and receive the predictions\n",
    "    '''\n",
    "    test_acc = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in test_set:\n",
    "        print(labels)\n",
    "        test_y_preds = predictor.predict(inputs)\n",
    "\n",
    "        _, preds_tensor = torch.max(torch.from_numpy(test_y_preds), 1)\n",
    "        preds = np.squeeze(preds_tensor.numpy()) if not use_cuda else np.squeeze(preds_tensor.cpu().numpy())\n",
    "\n",
    "        print(f\"preds is {preds}\")\n",
    "    \n",
    "        # compare the batch of predictions with the ground truth of labels\n",
    "        running_corrects += torch.sum(torch.from_numpy(preds) == labels)\n",
    "\n",
    "    test_acc = running_corrects.double() / len(test_set.dataset)\n",
    "\n",
    "    print('Acc: {:.2f}%'.format(test_acc*100))\n",
    "\n",
    "    return test_acc\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "testacc=test_acc(iter(dataloaders['test']), predictor)\n",
    "print(testacc)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
