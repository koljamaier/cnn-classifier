{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define imports\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "#import PIL\n",
    "import os, random\n",
    "\n",
    "from glob import glob\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from IPython.display import display, Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "\n",
    "\n",
    "import copy\n",
    "#import cv2                \n",
    "\n",
    "from io import open\n",
    "import json\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, os.path, random\n",
    "from PIL import Image\n",
    "import requests\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# my imports\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join, abspath\n",
    "from style_transfer.stylize import transfer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All images are resized to 224x224 and normalized\n",
    "# Only training images receive further augmentation\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogImages_style_transfer/valid\n",
      "{'train': 59800, 'valid': 835, 'test': 836}\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'dogImages_style_transfer'\n",
    "print(os.path.join(data_dir, 'valid'))\n",
    "\n",
    "\n",
    "# we create some dictionaries\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'valid', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=5,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'valid', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid', 'test']}\n",
    "print(dataset_sizes)\n",
    "class_names = image_datasets['train'].classes\n",
    "n_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create an S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# this is the S3 data_dir name\n",
    "data_dir = 'dogImages'\n",
    "train_dir = 'train'\n",
    "\n",
    "# set prefix, a descriptive name for a directory  \n",
    "prefix = 'capstone-project'\n",
    "\n",
    "# upload data for the first time; otherwise use the second expression (because the S3 upload takes some time)\n",
    "#train_location = sagemaker_session.upload_data(os.path.join(data_dir), key_prefix=prefix)\n",
    "train_location = 's3://{}/{}/'.format(bucket, prefix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your import and estimator code, here\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix)\n",
    "\n",
    "# note: this PyTorch estimator is specified with code that includes\n",
    "# the preprocessing with the imgaug library and is trained on the style\n",
    "# transferred images\n",
    "source_dir = 'source_pytorch'\n",
    "\n",
    "# instantiate a pytorch estimator\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                    source_dir=source_dir,\n",
    "                    role=role,\n",
    "                    framework_version='1.1.0',\n",
    "                    train_instance_count=1,\n",
    "                    #train_instance_type='ml.c4.xlarge',\n",
    "                    train_instance_type='ml.p2.xlarge',\n",
    "                    output_path=output_path,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    hyperparameters={\n",
    "                        'epochs': 10\n",
    "                    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-05 18:22:21 Starting - Starting the training job...\n",
      "2019-08-05 18:22:23 Starting - Launching requested ML instances......\n",
      "2019-08-05 18:23:23 Starting - Preparing the instances for training......\n",
      "2019-08-05 18:24:39 Downloading - Downloading input data................................................\n",
      "2019-08-05 18:32:50 Training - Training image download completed. Training in progress..\n",
      "\u001b[31mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[31mbash: no job control in this shell\u001b[0m\n",
      "\u001b[31m2019-08-05 18:32:51,640 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[31m2019-08-05 18:32:51,667 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[31m2019-08-05 18:32:51,974 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[31m2019-08-05 18:32:52,241 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2019-08-05 18:32:52,242 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2019-08-05 18:32:52,242 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2019-08-05 18:32:52,242 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mCollecting pillow==5.4.1 (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[31m  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\u001b[0m\n",
      "\u001b[31mCollecting imgaug==0.2.9 (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/17/a9/36de8c0e1ffb2d86f871cac60e5caa910cbbdb5f4741df5ef856c47f4445/imgaug-0.2.9-py2.py3-none-any.whl (753kB)\u001b[0m\n",
      "\u001b[31mCollecting Shapely (from imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/38/b6/b53f19062afd49bb5abd049aeed36f13bf8d57ef8f3fa07a5203531a0252/Shapely-1.6.4.post2-cp36-cp36m-manylinux1_x86_64.whl (1.5MB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (4.0.1.24)\u001b[0m\n",
      "\u001b[31mCollecting imageio (from imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/af/0a/943c965d372dae0b1f1482677d29030ab834351a61a9a632fd62f27f1523/imageio-2.5.0-py3-none-any.whl (3.3MB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (3.1.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (1.16.4)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (1.12.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.9->-r requirements.txt (line 2)) (1.3.0)\u001b[0m\n",
      "\u001b[31mCollecting scikit-image>=0.11.0 (from imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/ab/674e168bf7d0bc597218b3bec858d02c23fbac9ec1fec9cad878c6cee95f/scikit_image-0.15.0-cp36-cp36m-manylinux1_x86_64.whl (26.3MB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (2.8.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (2.4.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (1.1.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (0.10.0)\u001b[0m\n",
      "\u001b[31mCollecting networkx>=2.0 (from scikit-image>=0.11.0->imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/85/08/f20aef11d4c343b557e5de6b9548761811eb16e438cee3d32b1c66c8566b/networkx-2.3.zip (1.7MB)\u001b[0m\n",
      "\u001b[31mCollecting PyWavelets>=0.4.0 (from scikit-image>=0.11.0->imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/cd/528dba0b474b08f6f9a3a5e1b4bb23d8e33ed5d9f0e321cc967c2607df05/PyWavelets-1.0.3-cp36-cp36m-manylinux1_x86_64.whl (4.4MB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug==0.2.9->-r requirements.txt (line 2)) (41.0.1)\u001b[0m\n",
      "\u001b[31mCollecting decorator>=4.3.0 (from networkx>=2.0->scikit-image>=0.11.0->imgaug==0.2.9->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/5f/88/0075e461560a1e750a0dcbf77f1d9de775028c37a19a346a6c565a257399/decorator-4.4.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: train, networkx\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-f5o6d3vg/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[31m  Running setup.py bdist_wheel for networkx: started\n",
      "  Running setup.py bdist_wheel for networkx: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/de/63/64/3699be2a9d0ccdb37c7f16329acf3863fd76eda58c39c737af\u001b[0m\n",
      "\u001b[31mSuccessfully built train networkx\u001b[0m\n",
      "\u001b[31msagemaker-pytorch-container 1.2 has requirement Pillow==6.0.0, but you'll have pillow 5.4.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mInstalling collected packages: pillow, Shapely, imageio, decorator, networkx, PyWavelets, scikit-image, imgaug, train\n",
      "  Found existing installation: Pillow 6.0.0\n",
      "    Uninstalling Pillow-6.0.0:\n",
      "      Successfully uninstalled Pillow-6.0.0\u001b[0m\n",
      "\u001b[31mSuccessfully installed PyWavelets-1.0.3 Shapely-1.6.4.post2 decorator-4.4.0 imageio-2.5.0 imgaug-0.2.9 networkx-2.3 pillow-5.4.1 scikit-image-0.15.0 train-1.0.0\u001b[0m\n",
      "\u001b[31mYou are using pip version 18.1, however version 19.2.1 is available.\u001b[0m\n",
      "\u001b[31mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31m2019-08-05 18:33:00,494 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2019-08-05-18-22-20-825\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-central-1-505649883860/sagemaker-pytorch-2019-08-05-18-22-20-825/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[31mSM_HPS={\"epochs\":10}\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://sagemaker-eu-central-1-505649883860/sagemaker-pytorch-2019-08-05-18-22-20-825/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2019-08-05-18-22-20-825\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-central-1-505649883860/sagemaker-pytorch-2019-08-05-18-22-20-825/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--epochs\",\"10\"]\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[31mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m train --epochs 10\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mUsing device cuda.\u001b[0m\n",
      "\u001b[31mGet train data loader.\u001b[0m\n",
      "\u001b[31mEpoch: 1 #011Training Loss: 4.043044 #011Validation Loss: 1.632729\u001b[0m\n",
      "\u001b[31mEpoch: 2 #011Training Loss: 3.273106 #011Validation Loss: 1.045015\u001b[0m\n",
      "\u001b[31mEpoch: 3 #011Training Loss: 3.010815 #011Validation Loss: 0.834669\u001b[0m\n",
      "\u001b[31mEpoch: 4 #011Training Loss: 2.873254 #011Validation Loss: 0.721248\u001b[0m\n",
      "\u001b[31mEpoch: 5 #011Training Loss: 2.783619 #011Validation Loss: 0.661954\u001b[0m\n",
      "\u001b[31mEpoch: 6 #011Training Loss: 2.719921 #011Validation Loss: 0.619580\u001b[0m\n",
      "\u001b[31mEpoch: 7 #011Training Loss: 2.670455 #011Validation Loss: 0.589056\u001b[0m\n",
      "\u001b[31mEpoch: 8 #011Training Loss: 2.636757 #011Validation Loss: 0.563158\u001b[0m\n",
      "\u001b[31mEpoch: 9 #011Training Loss: 2.604821 #011Validation Loss: 0.545320\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train your estimator on S3 training data\n",
    "estimator.fit({'train': train_location})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-eu-central-1-505649883860/capstone-project/sagemaker-pytorch-2019-08-05-18-22-20-825/output/model.tar.gz\n",
      "CPU times: user 19.4 ms, sys: 98 µs, total: 19.4 ms\n",
      "Wall time: 91.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# importing PyTorchModel\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "print(estimator.model_data)\n",
    "\n",
    "# Create a model from the trained estimator data\n",
    "# And point to the prediction script\n",
    "model = PyTorchModel(model_data=estimator.model_data,\n",
    "                     role = role,\n",
    "                     framework_version='1.1.0',\n",
    "                     entry_point='predict.py',\n",
    "                     source_dir=source_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "# ATTENTION: Please use the ml.t2.large instance here. Otherwise the deployment will fail because of resource constraints\n",
    "# predictor = model.deploy(initial_instance_count=1, instance_type='ml.t2.medium')\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.t2.large')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 15,   6,  18,  61, 124])\n",
      "preds is [15  6 18 61 25]\n",
      "tensor([ 47,   1, 132,  70, 108])\n",
      "preds is [ 47  61 132  70 108]\n",
      "tensor([ 96,  40, 110,  36,  27])\n",
      "preds is [124  40 110  36  27]\n",
      "tensor([ 21,  29, 111,  38,   0])\n",
      "preds is [ 21  29 111  38   0]\n",
      "tensor([ 55,  40,  95,  16, 102])\n",
      "preds is [55 40 49 16 40]\n",
      "tensor([ 33,  90, 123,   3,  92])\n",
      "preds is [ 33  90 123  44  73]\n",
      "tensor([ 75,  66,  23,  40, 114])\n",
      "preds is [ 75  66  23  43 114]\n",
      "tensor([ 18,  35, 120,  80, 121])\n",
      "preds is [ 18  35 120  80  36]\n",
      "tensor([ 97, 106, 124, 114,  87])\n",
      "preds is [ 97 106 124 114  87]\n",
      "tensor([111,  13,  86,  72,   7])\n",
      "preds is [111  13  86  73   7]\n",
      "tensor([ 20,  58, 105, 104,  45])\n",
      "preds is [ 20  17 105  71  45]\n",
      "tensor([ 75, 114,  30, 109,  53])\n",
      "preds is [ 75 114  30 117  53]\n",
      "tensor([132,  17, 129,  61,  14])\n",
      "preds is [132  17 129  61  14]\n",
      "tensor([ 62,   9, 132,   5,  30])\n",
      "preds is [ 62   9 132   5  53]\n",
      "tensor([ 88,   6,  77, 123,  55])\n",
      "preds is [ 88  15  77 123 118]\n",
      "tensor([ 10, 126,  15,  36,  35])\n",
      "preds is [ 10 126  15  62  35]\n",
      "tensor([15, 82, 21, 59,  0])\n",
      "preds is [15 82 21 59  0]\n",
      "tensor([123,  40,  21,   7,  48])\n",
      "preds is [123  40  21   7  48]\n",
      "tensor([35, 82, 42, 55, 54])\n",
      "preds is [35 82 42 60 54]\n",
      "tensor([ 79,   4, 129,  10, 131])\n",
      "preds is [ 79   4  84  10 131]\n",
      "tensor([  5,   0,  67,  64, 108])\n",
      "preds is [  5   0  67  64 108]\n",
      "tensor([32, 98, 57, 12, 71])\n",
      "preds is [ 32  98  57 110  71]\n",
      "tensor([ 31,   5,  49,  53, 129])\n",
      "preds is [ 31   5  49  53 129]\n",
      "tensor([35, 23, 99,  8,  3])\n",
      "preds is [35 23 99 87  4]\n",
      "tensor([ 17,  22, 126,  75,  23])\n",
      "preds is [ 17  22 132  75  23]\n",
      "tensor([57, 51, 67, 81, 50])\n",
      "preds is [ 57  51  67 100  50]\n",
      "tensor([ 48,  24, 131,  70,   1])\n",
      "preds is [132  24 131  21 116]\n",
      "tensor([ 82, 102,  60,  13,  57])\n",
      "preds is [82 39 60 13 57]\n",
      "tensor([ 32,  65,  26,  18, 117])\n",
      "preds is [ 32  65  26  18 117]\n",
      "tensor([ 83, 100,  89,  94, 124])\n",
      "preds is [ 44 100  89  94 124]\n",
      "tensor([78, 91, 91,  3, 60])\n",
      "preds is [125  91  91   3  62]\n",
      "tensor([ 2, 61, 72, 11, 22])\n",
      "preds is [  2 129 130  11  22]\n",
      "tensor([ 91,  69,  20, 112,  57])\n",
      "preds is [ 91  69  20 112 100]\n",
      "tensor([ 49,  86,  50, 130, 111])\n",
      "preds is [ 49  86  50 130 111]\n",
      "tensor([128,   7,  18,  26, 102])\n",
      "preds is [ 75   7  18  26 102]\n",
      "tensor([67, 47, 48, 50, 43])\n",
      "preds is [ 67 122  48 105  43]\n",
      "tensor([69, 60, 15, 56, 54])\n",
      "preds is [69 62 15 56 54]\n",
      "tensor([ 23,  12,  45,  28, 109])\n",
      "preds is [ 23  12  45  28 109]\n",
      "tensor([ 68, 113,  94,  93,  36])\n",
      "preds is [ 68 113  78  93  36]\n",
      "tensor([ 84,  89,  31,   4, 101])\n",
      "preds is [ 84  89  31   4 101]\n",
      "tensor([105,  56,  20,  41,  39])\n",
      "preds is [105  56  25 126  39]\n",
      "tensor([114, 102,  87,   8, 116])\n",
      "preds is [114 102  87   8 116]\n",
      "tensor([ 78,  73, 123,  95,  55])\n",
      "preds is [ 94  73 123  46  55]\n",
      "tensor([ 35,  14, 107,  83,  60])\n",
      "preds is [ 35  14  83 114  60]\n",
      "tensor([19, 44,  4, 98, 41])\n",
      "preds is [ 19 117   4  81  41]\n",
      "tensor([112, 127,   1,   2,  75])\n",
      "preds is [112 127   1   2 111]\n",
      "tensor([33, 81, 53,  0, 67])\n",
      "preds is [33 81 53  0 67]\n",
      "tensor([32, 89, 62, 94, 10])\n",
      "preds is [32 89 62 94 42]\n",
      "tensor([26, 22, 37, 78, 37])\n",
      "preds is [26 22 37 78 37]\n",
      "tensor([ 34, 102, 129,  71, 119])\n",
      "preds is [ 34 102 129  95 119]\n",
      "tensor([  6,  12,  88,  56, 102])\n",
      "preds is [  6  12  88  56 102]\n",
      "tensor([106,  23,  68,  15,  73])\n",
      "preds is [106  23  68  15  73]\n",
      "tensor([106,  96,  39,  86, 101])\n",
      "preds is [106  96  39  86 101]\n",
      "tensor([ 81, 119,  90,  52,  73])\n",
      "preds is [124 119  90  75  73]\n",
      "tensor([57, 95, 30, 43, 83])\n",
      "preds is [57 95 53 43 83]\n",
      "tensor([121,   6,  34,  60, 103])\n",
      "preds is [ 71   6  34  60 103]\n",
      "tensor([ 5,  3, 74, 38,  0])\n",
      "preds is [ 5  3 74 38  0]\n",
      "tensor([117,  90,  72,  87,  81])\n",
      "preds is [117  90  62  87  81]\n",
      "tensor([106, 111,  34,  59, 110])\n",
      "preds is [106 111  34  59 110]\n",
      "tensor([110, 119,  98,  48,  44])\n",
      "preds is [110 119  99  48 117]\n",
      "tensor([119, 126,  52,  56,  52])\n",
      "preds is [119 132  52  56  52]\n",
      "tensor([ 7,  9, 93, 58, 51])\n",
      "preds is [ 7 94 93 58 51]\n",
      "tensor([117,  41,  40,  26,  55])\n",
      "preds is [117  41  40  26  55]\n",
      "tensor([ 77,  41,  51, 116,  28])\n",
      "preds is [ 80  41  51 116  28]\n",
      "tensor([ 90,  72, 103,   4,  35])\n",
      "preds is [ 90 130 103   4  35]\n",
      "tensor([110, 116,  16,  33,  29])\n",
      "preds is [110 116  16  33  29]\n",
      "tensor([27, 24, 31, 91, 32])\n",
      "preds is [121  24  31  91  73]\n",
      "tensor([120,   1,  79,  47,  16])\n",
      "preds is [120   1  79  47  16]\n",
      "tensor([ 90,  14, 124,  47, 108])\n",
      "preds is [ 90  14 124  47 108]\n",
      "tensor([46, 43, 38, 50,  6])\n",
      "preds is [46 43 38 50 15]\n",
      "tensor([49, 73, 62, 71, 13])\n",
      "preds is [ 59  73  62 121  42]\n",
      "tensor([114,  56,  44,  26,  99])\n",
      "preds is [114  56  44  26  99]\n",
      "tensor([43,  1, 59, 46, 52])\n",
      "preds is [ 7  1 59 46 63]\n",
      "tensor([ 13,  33,  81, 112,  62])\n",
      "preds is [ 13  33  99 112 119]\n",
      "tensor([131,  14,  77,  51, 128])\n",
      "preds is [131  14  43  62 128]\n",
      "tensor([25, 77, 34, 54, 74])\n",
      "preds is [73 31 65 54 74]\n",
      "tensor([85,  1, 82, 68, 39])\n",
      "preds is [85  1 82 68 39]\n",
      "tensor([ 28,  66, 127,  86,  21])\n",
      "preds is [28 66 89 86 21]\n",
      "tensor([115,  68,  47,  48,  88])\n",
      "preds is [115  68 114 123  88]\n",
      "tensor([ 53, 116,  58, 128,   9])\n",
      "preds is [ 53 116  58 128   9]\n",
      "tensor([117, 105,  28,  94,  69])\n",
      "preds is [117 105  28  78  69]\n",
      "tensor([38, 85, 29,  3, 17])\n",
      "preds is [38 85 29 66 17]\n",
      "tensor([15, 49, 89, 66, 76])\n",
      "preds is [15 49 89 66 76]\n",
      "tensor([121,  30,  59,  11, 105])\n",
      "preds is [ 71  30  59  11 105]\n",
      "tensor([ 21,  68, 115,  10, 100])\n",
      "preds is [ 21  68 115  42 100]\n",
      "tensor([86, 43, 17, 96, 41])\n",
      "preds is [86 68 17  2 41]\n",
      "tensor([83, 42,  8, 70, 19])\n",
      "preds is [83 42 54 70 19]\n",
      "tensor([106,   3,  45, 117,  28])\n",
      "preds is [106   3  45 117  28]\n",
      "tensor([ 70,  81, 109,  87,  62])\n",
      "preds is [ 70  99 117 123  62]\n",
      "tensor([ 52,  75,  31,   7, 121])\n",
      "preds is [129  75  31   7 121]\n",
      "tensor([  7,  24, 113,  64,  28])\n",
      "preds is [  7  24 113  64  28]\n",
      "tensor([ 62, 122,  53,  43,  80])\n",
      "preds is [ 62 122  53  43  80]\n",
      "tensor([ 5, 61, 54, 89, 10])\n",
      "preds is [ 5 61 54 89 10]\n",
      "tensor([ 45, 112,  79,  35, 128])\n",
      "preds is [ 45 112  79  35 128]\n",
      "tensor([ 76,  93, 122,  48,   5])\n",
      "preds is [ 76  93 122  48   5]\n",
      "tensor([ 71, 127,  58, 103, 112])\n",
      "preds is [ 71 127  69 103 112]\n",
      "tensor([122,  96,  96,  39,  51])\n",
      "preds is [122  25  96  39  51]\n",
      "tensor([63, 98, 45, 22, 15])\n",
      "preds is [63 98 45 22 15]\n",
      "tensor([126,  20,  12,  78,  34])\n",
      "preds is [132  20  12  94  95]\n",
      "tensor([63, 46, 57, 97, 12])\n",
      "preds is [ 45  46  57  97 126]\n",
      "tensor([35,  6,  9, 16, 30])\n",
      "preds is [35  6  9 16 30]\n",
      "tensor([  9,  58,  33, 100,  40])\n",
      "preds is [125  69  33 100  33]\n",
      "tensor([ 45, 111,  55, 115,   4])\n",
      "preds is [ 76 111  69 115   4]\n",
      "tensor([64, 84, 96, 11, 76])\n",
      "preds is [ 79 129   2  11  76]\n",
      "tensor([120,  45,  54,  45, 109])\n",
      "preds is [120  45  54  45 127]\n",
      "tensor([ 81,  69, 116,  86,  74])\n",
      "preds is [ 81 101 116  86  57]\n",
      "tensor([68, 22, 85, 19, 75])\n",
      "preds is [68 22 85 19 75]\n",
      "tensor([86, 40, 89, 68,  1])\n",
      "preds is [86 40 89 68  1]\n",
      "tensor([ 99,  97,  70,  55, 117])\n",
      "preds is [ 99  97  70  55 117]\n",
      "tensor([25, 18, 25, 80, 44])\n",
      "preds is [25 18 25 89 44]\n",
      "tensor([17, 67, 78, 20, 67])\n",
      "preds is [ 17 105  78  20  67]\n",
      "tensor([ 69,  33, 130,  75,   5])\n",
      "preds is [101  33 130  75   5]\n",
      "tensor([62, 92, 28, 43, 54])\n",
      "preds is [ 62  25  28  43 123]\n",
      "tensor([33, 16, 46, 36,  7])\n",
      "preds is [33 16 46 36  7]\n",
      "tensor([97, 88, 85, 22, 53])\n",
      "preds is [97 88 85 22 53]\n",
      "tensor([110, 127,  10,  19,  80])\n",
      "preds is [110 127  10  19  80]\n",
      "tensor([24, 19, 54, 29, 14])\n",
      "preds is [55 19 54 29 14]\n",
      "tensor([ 88,   1, 100, 108,  83])\n",
      "preds is [ 88   1 100 108 117]\n",
      "tensor([ 56, 128,  80,  65,  10])\n",
      "preds is [ 56 128  69  65  10]\n",
      "tensor([ 44,  67, 119,  59,   6])\n",
      "preds is [ 44  67 119  59  15]\n",
      "tensor([ 4, 63, 14, 56, 53])\n",
      "preds is [ 4 63 14 56 53]\n",
      "tensor([16, 38, 74, 39, 29])\n",
      "preds is [16 38 74 39 29]\n",
      "tensor([22,  0, 85, 60, 52])\n",
      "preds is [22  0 85 60 62]\n",
      "tensor([51, 94, 36, 46, 38])\n",
      "preds is [51 94 36 46 38]\n",
      "tensor([103,  11,  21,  37,  42])\n",
      "preds is [103  11  21  37  66]\n",
      "tensor([ 26,  56,  84,  50, 105])\n",
      "preds is [ 26  56 129  50 105]\n",
      "tensor([23, 25, 36, 64, 59])\n",
      "preds is [23 25 36 64 59]\n",
      "tensor([ 84, 114,  90,  22,  76])\n",
      "preds is [129 114  90  22  76]\n",
      "tensor([ 93, 105, 101,  50,  37])\n",
      "preds is [ 93 105 101  50  37]\n",
      "tensor([ 2, 78, 11,  4, 14])\n",
      "preds is [ 2 94 11  4 14]\n",
      "tensor([ 11,  79,  65,  86, 103])\n",
      "preds is [111  79  65  86 103]\n",
      "tensor([59,  2, 38, 71, 63])\n",
      "preds is [ 59   2  38 121  45]\n",
      "tensor([106, 100,  31,  91,  29])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds is [106 100  31  91  29]\n",
      "tensor([16, 56, 20, 42, 61])\n",
      "preds is [ 16  56  20  75 129]\n",
      "tensor([42, 95, 15, 88, 23])\n",
      "preds is [42 95 15 74 23]\n",
      "tensor([ 97,  39,  20, 115,  10])\n",
      "preds is [ 97  39  20 115 117]\n",
      "tensor([108,  37, 100,  70,  85])\n",
      "preds is [ 91 132 100  70  85]\n",
      "tensor([ 30,  14, 122,  19, 104])\n",
      "preds is [ 30  14 114  19 104]\n",
      "tensor([107,   3,  18,  17,  43])\n",
      "preds is [107   3  18  58   7]\n",
      "tensor([ 41, 122,  40,  95,  26])\n",
      "preds is [ 41 122  40  95  26]\n",
      "tensor([77,  0, 31,  0, 88])\n",
      "preds is [77 98 31  0 88]\n",
      "tensor([50, 57,  2,  9,  4])\n",
      "preds is [50 57  2  9  4]\n",
      "tensor([78, 89, 41, 38, 46])\n",
      "preds is [ 78  89 110  38  46]\n",
      "tensor([ 39, 118,  59, 118, 102])\n",
      "preds is [ 39 118  59  16 102]\n",
      "tensor([19, 74, 98, 42, 80])\n",
      "preds is [ 19 113  98  42  89]\n",
      "tensor([ 20,  37,  11,  89, 111])\n",
      "preds is [ 20  37  11 119 111]\n",
      "tensor([ 38,  65, 128,  44,  47])\n",
      "preds is [38 65 50 44 47]\n",
      "tensor([ 4, 63, 81, 13, 27])\n",
      "preds is [ 4 63 81 13 27]\n",
      "tensor([ 64,  13, 125, 129, 114])\n",
      "preds is [ 64  13 125 129 114]\n",
      "tensor([ 28,  79, 123,  66, 132])\n",
      "preds is [ 28  79 123  66 132]\n",
      "tensor([111, 123,  44, 114,   4])\n",
      "preds is [111 123  44 114   4]\n",
      "tensor([ 58, 116, 117,  19,  87])\n",
      "preds is [ 69 116 117  19  87]\n",
      "tensor([13, 72, 13, 70, 34])\n",
      "preds is [ 13 130  13 108  34]\n",
      "tensor([ 37,  71,  49, 113,  23])\n",
      "preds is [ 37  71  59 113  23]\n",
      "tensor([78, 11, 47, 87, 60])\n",
      "preds is [78 11 47 87 76]\n",
      "tensor([ 49, 126,  14,  61,  92])\n",
      "preds is [ 49 126  14  61  92]\n",
      "tensor([113, 125,  40,  90,  55])\n",
      "preds is [113 125  40  90  55]\n",
      "tensor([30, 28, 83, 32,  2])\n",
      "preds is [30 28 83 32  2]\n",
      "tensor([ 26,  75,  12, 107,  25])\n",
      "preds is [ 26  75  12 109  25]\n",
      "tensor([ 31, 118,   5,  14,  11])\n",
      "preds is [ 31 118 122  14  11]\n",
      "tensor([ 28, 130,  76,  13,  29])\n",
      "preds is [ 28 130  76  13  29]\n",
      "tensor([92, 27, 31, 94, 69])\n",
      "preds is [124  27  31  78  69]\n",
      "tensor([ 33, 104,  70, 118,  93])\n",
      "preds is [ 33 104  70 118  93]\n",
      "tensor([85,  7, 99,  8, 80])\n",
      "preds is [ 85   7 103  34  80]\n",
      "tensor([ 16, 104,  82,  17,  60])\n",
      "preds is [ 16 104  82  17  60]\n",
      "tensor([ 55,  46,  41,  82, 125])\n",
      "preds is [113  46  41  82 125]\n",
      "tensor([10,  3, 67, 73, 50])\n",
      "preds is [10  3 67 73 50]\n",
      "tensor([45])\n",
      "preds is 76\n",
      "Acc: 81.58%\n",
      "tensor(0.8158, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "def test_acc(test_set, predictor):\n",
    "    ''' \n",
    "    This method calculates our accuracy metric. For this, it will send \n",
    "    batches of data to the endpoint and receive the predictions\n",
    "    '''\n",
    "    test_acc = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in test_set:\n",
    "        print(labels)\n",
    "        test_y_preds = predictor.predict(inputs)\n",
    "\n",
    "        _, preds_tensor = torch.max(torch.from_numpy(test_y_preds), 1)\n",
    "        preds = np.squeeze(preds_tensor.numpy()) if not use_cuda else np.squeeze(preds_tensor.cpu().numpy())\n",
    "\n",
    "        print(f\"preds is {preds}\")\n",
    "    \n",
    "        # compare the batch of predictions with the ground truth of labels\n",
    "        running_corrects += torch.sum(torch.from_numpy(preds) == labels)\n",
    "\n",
    "    test_acc = running_corrects.double() / len(test_set.dataset)\n",
    "\n",
    "    print('Acc: {:.2f}%'.format(test_acc*100))\n",
    "\n",
    "    return test_acc\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "testacc=test_acc(iter(dataloaders['test']), predictor)\n",
    "print(testacc)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
